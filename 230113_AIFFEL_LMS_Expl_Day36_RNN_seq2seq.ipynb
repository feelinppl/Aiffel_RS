{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> RNN seq2seq </center>\n",
    "\n",
    "# ë“¤ì–´ê°€ë©°\n",
    "í˜„ì¬ ë„ë¦¬ ì‚¬ìš©ë˜ê³  ìˆëŠ” ê°€ì¥ ì„±ê³µì ì¸ ì¸ê³µì§€ëŠ¥ ì–´í”Œë¦¬ì¼€ì´ì…˜ì„ í•˜ë‚˜ ê¼½ìœ¼ë¼ê³  í•œë‹¤ë©´, ë‹¨ì—°ì½” ì‹ ê²½ë§ ê¸°ê³„ ë²ˆì—­(Neural Machine Translation)ì¼ ê²ƒì…ë‹ˆë‹¤. ì´ë¯¸ êµ¬ê¸€ë²ˆì—­, íŒŒíŒŒê³  ë“± ìš°ë¦¬ê°€ ì‚¬ìš©í•˜ê³  ìˆëŠ” ë²ˆì—­ê¸°ì˜ ìˆ˜ì¤€ì€ ë†€ë¼ìš¸ ì •ë„ì…ë‹ˆë‹¤. ì¸ê³µì§€ëŠ¥ì„ í†µí•´ ê·¸í† ë¡ ë„˜ì–´ì„œê¸° ì–´ë µë˜ ì–¸ì–´ì˜ ì¥ë²½ì´ í•œì¸µ ë‚®ì•„ì¡Œë‹¤ëŠ” ê²ƒì´ ì´ì œëŠ” ë„ˆë¬´ë‚˜ ìì—°ìŠ¤ëŸ½ê¸°ë§Œ í•©ë‹ˆë‹¤.\n",
    "\n",
    "ì˜¤ëŠ˜ ìš°ë¦¬ê°€ ë°°ìš°ê²Œ ë  sequence-to-sequence(seq2seqì´ë¼ê³  ë§ì´ ë¶€ë¦…ë‹ˆë‹¤) ëª¨ë¸ì€ ì´ëŸ¬í•œ ë‰´ëŸ´ ê¸°ê³„ë²ˆì—­ì˜ ê°€ëŠ¥ì„±ì„ í•œì¸µ ì•ë‹¹ê¸´ ê¸°ë…ë¹„ì ì¸ ëª¨ë¸ì´ë¼ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë¬¼ë¡  ì§€ê¸ˆ ì—„ì²­ë‚œ ì„±ëŠ¥ì„ ë‚´ê³  ìˆëŠ” ê¸°ê³„ë²ˆì—­ ëª¨ë¸ì— ì‚¬ìš©ë˜ê³  ìˆì§€ëŠ” ì•ŠìŠµë‹ˆë‹¤. ì•ìœ¼ë¡œ ë°°ìš°ê²Œ ë  ìµœì‹  ëª¨ë¸ë“¤ì— ë¹„í•˜ë©´ seq2seqì€ ê³ ì „ì ì´ë¼ê³  í•  ìˆ˜ ìˆê² ìŠµë‹ˆë‹¤ë§Œ, ì§€ê¸ˆì˜ ë²ˆì—­ê¸° ëª¨ë¸ì˜ ê·¼ê°„ì„ ì´ë£¨ê³  ìˆëŠ” ì¤‘ìš”í•œ ì•„ì´ë””ì–´ë¥¼ ì œê³µí•˜ê³  ìˆìŠµë‹ˆë‹¤. 2014ë…„ ì²˜ìŒ ë‚˜ì™”ì„ ë‹¹ì‹œ sequence-to-sequenceì€ ë§¤ìš° ê¹Šì€ ì¸ìƒì„ ë‚¨ê²¼ìŠµë‹ˆë‹¤. ë”¥ëŸ¬ë‹ì„ í†µí•´ ì–´ë–¤ ë³µì¡í•œ ê²ƒ(X)ë„ ë‹¤ë¥¸ ê²ƒ(Y)ë¡œ ë°”ê¿€ ìˆ˜ ìˆë‹¤ë¼ëŠ” ìƒê°ì´ ì—¬ëŸ¬ê°€ì§€ X-to-Y ëª¨ë¸ì˜ ë³€ì¢…ì„ ë§Œë“¤ì–´ ëƒˆìŠµë‹ˆë‹¤. Image-to-Text , Voice-to-Text ë“± ë‹¤ì–‘í•œ ì•„ì´ë””ì–´ê°€ ë‚˜ì˜¤ê³ , ì´ë¥¼ í†µí•´ ë”¥ëŸ¬ë‹ ê¸°ìˆ ì´ í•œë‹¨ê³„ ë„ì•½í•˜ëŠ” ê³„ê¸°ê°€ ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ê·¸ëŸ¬í•œ seq2seq ëª¨ë¸ì„ ë§Œë“¤ì–´ ë³´ë©´ì„œ, ë²ˆì—­ê¸°ì˜ ê¸°ë³¸ì ì¸ ì•„ì´ë””ì–´ì— ëŒ€í•´ì„œë„ ìƒì„¸íˆ íŒŒì•…í•´ ë³´ê² ìŠµë‹ˆë‹¤.\n",
    "\n",
    "# í•™ìŠµ ëª©í‘œ\n",
    "---\n",
    "1. ë‹¤ì–‘í•œ RNNì˜ êµ¬ì„±ì„ ì•Œì•„ë³´ê¸°\n",
    "2. ì¸ì½”ë”ì™€ ë””ì½”ë” êµ¬ì¡°ì˜ í•„ìš”ì„± ì´í•´í•˜ê¸°\n",
    "3. êµì‚¬ ê°•ìš”(teacher forcing)ì˜ ì›ë¦¬ ì•Œê¸°\n",
    "4. í›ˆë ¨ ë‹¨ê³„ì™€ ì¶”ë¡  ë‹¨ê³„(inference)ì˜ ì°¨ì´ ì•Œê¸°"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](https://d3s0tskafalll9.cloudfront.net/media/images/E-15-1.machine_translation.max-800x600.png)\n",
    "\n",
    "1940ë…„ëŒ€ë¶€í„° 1980ë…„ëŒ€ê¹Œì§€ì˜ ê¸°ê³„ ë²ˆì—­ì€ ê·œì¹™ ê¸°ë°˜ì˜ ê¸°ê³„ ë²ˆì—­(Rule-based Machine Translation) ì´ ì£¼ë¥¼ ì´ë¤˜ìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, 2ì°¨ ì„¸ê³„ ëŒ€ì „ ì‹œì ˆ ë¯¸êµ­ì´ ëŸ¬ì‹œì•„ì–´ë¥¼ ì˜ì–´ë¡œ ë²ˆì—­í•˜ê³ ì í–ˆì„ë•Œ, ëŸ¬ì‹œì•„ ë¬¸ì¥ì—ì„œ ë‹¨ì–´ í•˜ë‚˜, í•˜ë‚˜ì˜ ì˜ë¯¸ë¥¼ ë¶„ì„í•˜ê³ , ê·¸ ë‹¨ì–´ë“¤ì´ ì–´ë–»ê²Œ ë¬¸ë²•ì ìœ¼ë¡œ ì—°ê²°ë˜ì—ˆëŠ”ì§€ë¥¼ ë¶„ì„í•˜ê³ , ê·¸ ë‹¤ìŒ êµ¬ì¡° ìƒì˜ ì˜ë¯¸ë¥¼ ë¶„ì„í•œ ë’¤ì—, ê·¸ì œì„œì•¼ ì˜ì–´ì™€ ì˜ë¯¸ì ìœ¼ë¡œ ë§ê²Œ ë‹¨ì–´ë“¤ì„ ë¶„ë¦¬í•˜ê³ , ë§ˆì§€ë§‰ìœ¼ë¡œ ì˜ì–´ ë¬¸ë²•ì— ë§ê²Œ ë‹¤ì‹œ ë‹¨ì–´ë“¤ì˜ ìˆœì„œë¥¼ ë§ì¶”ê³ ... ì´ì•¼ê¸°ë§Œ ë“¤ì–´ë„ êµ‰ì¥íˆ ë³µì¡í–ˆì„ ê²ƒ ê°™ìŠµë‹ˆë‹¤.\n",
    "\n",
    "![image](https://d3s0tskafalll9.cloudfront.net/media/original_images/E-15-2.ibm_paper.png)\n",
    "\n",
    "1980ë…„ í›„ë°˜ì— ë“¤ì–´ì„œ IBMì—ì„œ ê·œì¹™ ê¸°ë°˜ì—ì„œ ë²—ì–´ë‚˜ë ¤ëŠ” ì‹œë„ê°€ ìˆì—ˆìŠµë‹ˆë‹¤. ì–¸ì–´í•™ ê¸°ë°˜ì˜ ê·œì¹™ì´ ì•„ë‹Œ í†µê³„ë¡œ êµ¬í˜„í•˜ë ¤ëŠ” ì‹œë„ì˜€ëŠ”ë°ìš”. ì´ë¥¼ í†µê³„ì  ê¸°ê³„ ë²ˆì—­(Statistical Machine Translation) ì´ë¼ê³  í•©ë‹ˆë‹¤. 1980ë…„ëŒ€ ë‹¹ì‹œ ê·œì¹™ ê¸°ë°˜ì˜ ì ‘ê·¼ì´ ì–¼ë§ˆë‚˜ ë‹µë‹µí–ˆëŠ”ì§€ ê·¸ íŒ€ì˜ ë¦¬ë” í”„ë ˆë°ë¦¬ ì œë¦¬ë„¥ì€ ì´ ë‹¹ì‹œ \"ë§¤ë²ˆ ë‚´ê°€ ì–¸ì–´í•™ìë¥¼ í•´ê³ í•  ë•Œë§ˆë‹¤, ì–¸ì–´ ì¸ì‹ê¸°ì˜ ì„±ëŠ¥ì´ ì˜¬ë¼ê°”ë‹¤.\" ë¼ëŠ” ë§ì„ ë‚¨ê²¼ë‹¤ëŠ” ì†Œë¬¸ì´ ìˆì£ . ì´ ë°©ë²•ì€ 2010ë…„ ì¤‘ë°˜ê¹Œì§€ ì£¼ìš”í•œ ì ‘ê·¼ìœ¼ë¡œ ì‚¬ìš©ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "í†µê³„ ê¸°ë°˜ ë²ˆì—­ì— ì—¬ëŸ¬ ë¨¸ì‹  ëŸ¬ë‹ ê¸°ë²•ì´ ì‚¬ìš©ë˜ì—ˆì§€ë§Œ ë”¥ ëŸ¬ë‹ì€ ì•„ë‹ˆì—ˆìŠµë‹ˆë‹¤. ì¸ê³µ ì‹ ê²½ë§ìœ¼ë¡œ ë²ˆì—­ì„ ì œì•ˆí•˜ëŠ” ë…¼ë¬¸ì€ ëª‡ í¸ ìˆì—ˆì§€ë§Œ, í›ˆë ¨ ë°ì´í„°ë„ ì ê³  ì‹ ê²½ë§ì˜ í¬ê¸°ë„ ì‘ì•„ì„œ ì£¼ëª©ë°›ì§€ ëª»í–ˆì£ . ê·¸ëŸ¬ë‚˜ 2010ë…„ ì¤‘ë°˜ì— ë“¤ì–´ ì•Œê³ ë¦¬ì¦˜ê³¼ í•˜ë“œì›¨ì–´ì˜ ë°œì „ìœ¼ë¡œ ë”¥ ëŸ¬ë‹ì´ ë¹›ì„ ë°œí•˜ë©´ì„œ ë‹¬ë¼ì¡ŒìŠµë‹ˆë‹¤.\n",
    "\n",
    "êµ¬ê¸€ì€ 2016ë…„ 9ì›”. ìì‹ ë“¤ì˜ êµ¬ê¸€ ë²ˆì—­ê¸°ì— ì‹ ê²½ë§ ê¸°ê³„ ë²ˆì—­(Neural Machine Translation, NMT) ì„ ë„ì…í•˜ë©´ì„œ íšê¸°ì ì¸ ì„±ëŠ¥ ê°œì„ ì„ ì´ë¤˜ë‹¤ê³  ë°œí‘œí–ˆìŠµë‹ˆë‹¤. í†µê³„ ê¸°ë°˜ ë²ˆì—­ì—ì„œ ì‹ ê²½ë§ ê¸°ê³„ ë²ˆì—­ìœ¼ë¡œ ë³€ê²½ë˜ë©´ì„œ, í•œì¸µ ë” ë†’ì€ ìˆ˜ì¤€ì˜ ë²ˆì—­ ëŠ¥ë ¥ì„ ê°€ì§ˆ ìˆ˜ ìˆê²Œ ë˜ì—ˆëŠ”ë°ìš”. ì´ë•Œ ì‚¬ìš©ëœ ì¸ê³µ ì‹ ê²½ë§ì´ seq2seq ì…ë‹ˆë‹¤. (ë¬¼ë¡  ì‹¤ì œë¡œëŠ” ëª‡ ê°€ì§€ ì¶”ê°€ì ì¸ ë©”ì»¤ë‹ˆì¦˜ì´ ë“¤ì–´ê°€ìˆìŠµë‹ˆë‹¤.) ì´ë²ˆ ì±•í„°ì—ì„œëŠ” ì´ ì‹ ê²½ë§ seq2seqë¥¼ êµ¬í˜„í•´ì„œ ê¸°ê³„ ë²ˆì—­ê¸°ë¥¼ ë§Œë“¤ì–´ë³¼ê±°ì—ìš”."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ì‹œí€€ìŠ¤ ì²˜ë¦¬í•˜ëŠ” RNN\n",
    "ì•ì„œ ì‹œí€€ìŠ¤ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•˜ëŠ” RNNì— ëŒ€í•´ì„œ ë°°ì› ìŠµë‹ˆë‹¤. RNNì€ ì–´ë–»ê²Œ í™œìš©í•˜ëŠëƒì— ë”°ë¼ì„œ ë‹¤ì–‘í•œ ì–´í”Œë¦¬ì¼€ì´ì…˜ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ”ë°ìš”.\n",
    "![image](https://d3s0tskafalll9.cloudfront.net/media/images/E-15-3.rnn_effectiveness.max-800x600.jpg)\n",
    "\n",
    "ìœ„ì˜ ê·¸ë¦¼ì€ ë‹¤ì–‘í•œ RNNì˜ í™œìš© ë°©ë²•ì„ ë³´ì—¬ì£¼ê³  ìˆìŠµë‹ˆë‹¤. ì¢Œì¸¡ë¶€í„° ì°¨ë¡€ëŒ€ë¡œ 1ë²ˆë¶€í„° 5ë²ˆì´ë¼ê³  ë²ˆí˜¸ë¥¼ ë¶™ì˜€ë‹¤ê³  ê°€ì •í•˜ê³  ì„¤ëª…í•´ë³¼ê¹Œìš”? 1ë²ˆ one-to-oneì€ ìˆœí™˜í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ ì¼ë°˜ì ì¸ í”¼ë“œ í¬ì›Œë“œ ì‹ ê²½ë§ì…ë‹ˆë‹¤. 2ë²ˆ one-to-manyëŠ” ìˆœí™˜ì„ í•˜ê¸° ì‹œì‘í•˜ë‹ˆê¹Œ ë³¸ê²©ì ì¸ RNNì´ë„¤ìš”. í•˜ë‚˜ì˜ ì…ë ¥ìœ¼ë¡œë¶€í„° ë‹¤ìˆ˜ì˜ ì¶œë ¥ì„ ë‚´ëŠ” ê²½ìš°ì¸ë°, ì˜ˆë¥¼ ë“¤ì–´ í•˜ë‚˜ì˜ ì´ë¯¸ì§€ë¥¼ ë°›ì•„ì„œ ì´ë¯¸ì§€ì˜ ì œëª©, ë‹¤ì‹œ ë§í•´ ë‹¨ì–´ ì‹œí€€ìŠ¤ë¥¼ ì¶œë ¥í•˜ëŠ” ì´ë¯¸ì§€ ìº¡ì…”ë‹(image captioning) ì‘ì—…ì´ ì´ì— ì†í•©ë‹ˆë‹¤.\n",
    "\n",
    "2ë²ˆê³¼ ë°˜ëŒ€ì²˜ëŸ¼ ë³´ì´ëŠ” 3ë²ˆ many-to-oneì€ ì‹œí€€ìŠ¤ë¥¼ ì…ë ¥ë°›ì•„ì„œ í•˜ë‚˜ì˜ ê²°ê³¼ë¥¼ ë‚´ëŠ” RNNìœ¼ë¡œ í…ìŠ¤íŠ¸ ë¶„ë¥˜(text classification)ì— ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê°€ë ¹, ìŠ¤íŒ¸ ë©”ì¼ ë¶„ë¥˜ê¸°ë¼ê³  í•˜ë©´ ë©”ì¼ì„ ì…ë ¥ë°›ì•„ì„œ ì´ ë©”ì¼ì´ 'ì •ìƒ ë©”ì¼'ì¸ì§€ 'ìŠ¤íŒ¸ ë©”ì¼'ì¸ì§€ë¥¼ ê²°ê³¼ë¥¼ ì•Œ ìˆ˜ ìˆê² ì£ .\n",
    "\n",
    "5ë²ˆìœ¼ë¡œ ê°€ë³¼ê²Œìš”. 5ë²ˆ many-to-manyëŠ” ì‹œí€€ìŠ¤ë¥¼ ì…ë ¥ë°›ì•„ ì‹œí€€ìŠ¤ë¥¼ ì¶œë ¥í•˜ëŠ”ë°, ë§¤ time stepë§ˆë‹¤ ë°”ë¡œ ì¶œë ¥ì„ í•˜ëŠ” êµ¬ì¡°ì—ìš”. ì´ êµ¬ì¡°ëŠ” ì…ë ¥ ë¬¸ì¥ì˜ ê° ë‹¨ì–´ê°€ ë¬´ì—‡ì¸ì§€ë¥¼ ì•Œë ¤ì£¼ëŠ” ê°œì²´ëª… ì¸ì‹ì´ë‚˜ í’ˆì‚¬ íƒœê¹…ì— ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ì´ì œ 4ë²ˆì„ ë³¼ê¹Œìš”? many-to-manyì´ì§€ë§Œ 5ë²ˆì´ë‘ ë‹¬ë¼ìš”. ì…ë ¥ì„ ë°›ëŠ” ë™ì•ˆ ì¶œë ¥ì„ ë‚´ì§€ ì•Šë‹¤ê°€ ì–´ëŠ time stepë¶€í„° ì¶œë ¥ì„ ì‹œì‘í•©ë‹ˆë‹¤. ì•„ë§ˆ ì–´ë–¤ ê¸°ì¤€ì´ ìˆëŠ” ëª¨ì–‘ì´ì—ìš”. êµ¬í˜„í•˜ê¸°ê°€ 5ë²ˆë³´ë‹¤ëŠ” ê¹Œë‹¤ë¡œìš¸ ê²ƒ ê°™ë‹¤ëŠ” ìƒê°ì´ ë“­ë‹ˆë‹¤.\n",
    "\n",
    "ì‚¬ì‹¤, ê¸°ê³„ ë²ˆì—­ê¸° êµ¬í˜„ì€ ê¸°ë³¸ì ìœ¼ë¡œ 4ë²ˆì„ í™œìš©í•´ì•¼ í•´ìš”. ê·¸ ì´ìœ ëŠ” 'ì‚¬ëŒ ë§ì€ ëê¹Œì§€ ë“¤ì–´ë´ì•¼í•œë‹¤' ë¼ëŠ” í˜„ì¸(?)ë“¤ì˜ ë§ê³¼ ì—°ê´€ì´ ìˆëŠ”ë°ìš”. ë²ˆì—­ ë˜ëŠ” í†µì—­ì´ë¼ê³  í•˜ëŠ” ê²ƒì€ ì „ì²´ ë¬¸ì¥ì„ ëª¨ë‘ ì½ê±°ë‚˜ ë“£ê³ ë‚˜ì„œì•¼ í•  ìˆ˜ ìˆê¸° ë•Œë¬¸ì´ì£ . ë²ˆì—­ì´ë‚˜ í†µì—­ì— 5ë²ˆì„ ì‚¬ìš©í•˜ë©´ ì•„ì§ ì‚¬ëŒ ë§ì´ ë‹¤ ì•ˆ ëë‚¬ëŠ”ë° ë‹¨ì–´ í•˜ë‚˜ë¥¼ ë“¤ì„ ë•Œë§ˆë‹¤ ê·¸ ìˆœê°„ ë²ˆì—­í•œë‹¤ëŠ” ëœ»ì¸ë° ê·¸ ìµœì¢… ë²ˆì—­ì´ ì œëŒ€ë¡œ ëœ ë¬¸ì¥ì¼ë¦¬ê°€ ì—†ê² ì£ ?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## seq2seq\n",
    "\n",
    "### seq2seqì˜ ì¸ì½”ë”-ë””ì½”ë” êµ¬ì¡°\n",
    "ì•ì„œ ë²ˆì—­ê¸°ëŠ” ë‹¤ì–‘í•œ RNNì˜ ìœ í˜• ê·¸ë¦¼ì¤‘ì—ì„œë„ 4ë²ˆì„ ì‚¬ìš©í•œë‹¤ê³  í–ˆì—ˆì£ ? ì‚¬ì‹¤ ë” ìì„¸íˆ ë§í•˜ë©´ 4ë²ˆ ê·¸ë¦¼ë³´ë‹¤ ì¡°ê¸ˆ~ ë” ë³µì¡í•©ë‹ˆë‹¤. ì•„ë˜ì˜ ê·¸ë¦¼ì€ ë²ˆì—­ê¸°ì˜ ê¸°ë³¸ êµ¬ì¡°ì¸ seq2seq ì…ë‹ˆë‹¤.\n",
    "\n",
    "![image](https://d3s0tskafalll9.cloudfront.net/media/images/E-15-4.seq2seq.max-800x600.jpg)\n",
    "\n",
    "seq2seqëŠ” ë‘ ê°œì˜ RNN ì•„í‚¤í…ì²˜ë¥¼ ì—°ê²°í•œ êµ¬ì¡°ì…ë‹ˆë‹¤. ì…ë ¥ ë¬¸ì¥ì„ ë°›ëŠ” RNNì„ ì¸ì½”ë”ë¼ê³  í•˜ê³ , ë‘ë²ˆì§¸ RNNì„ ë””ì½”ë”ë¼ê³  í•©ë‹ˆë‹¤.\n",
    "\n",
    "ì•„ë˜ ê·¸ë¦¼ì—ì„œ EncoderëŠ” Feature Extractorì˜ ì—­í• ì„ í•©ë‹ˆë‹¤. ì–´ë–¤ ë°ì´í„° Xë¥¼ í•´ì„í•˜ê¸° ìœ„í•œ ì €ì°¨ì›ì˜ feature vector zë¥¼ ë§Œë“¤ì–´ ëƒ…ë‹ˆë‹¤. ë°˜ë©´ì— DecoderëŠ” ì €ì°¨ì›ì˜ Feature zë¡œë¶€í„° ì •ë³´ë¥¼ ë³µì›í•´ì„œ ë‹¤ì‹œ ì–´ë–¤ ë°ì´í„° $\\primeX $ ì„ ì¬ìƒì„±í•˜ëŠ” ì—­í• ì„ í•©ë‹ˆë‹¤.\n",
    "\n",
    " ![image](https://d3s0tskafalll9.cloudfront.net/media/images/E-15-5.encdec.max-800x600.png)\n",
    "\n",
    "ìš°ë¦¬ê°€ ì˜¤ëŠ˜ ë§Œë“¤ seq2seq ëª¨ë¸ì€ ìœ„ ì¸ì½”ë”-ë””ì½”ë” ëª¨ë¸ì—ì„œ ì¸ì½”ë”ì™€ ë””ì½”ë” ëª¨ë¸ì´ ëª¨ë‘ RNNì¸ ê²½ìš°ë¼ê³  ë³¼ ìˆ˜ ìˆì„ ê²ƒì…ë‹ˆë‹¤. ê·¸ë ‡ë‹¤ë©´ seq2seqì˜ feature vectorëŠ” ë¬´ì—‡ì¼ê¹Œìš”? ë°”ë¡œ ì¸ì½”ë” RNNì´ ì…ë ¥ë¬¸ì¥ì„ í•´ì„í•´ì„œ ë§Œë“¤ì–´ ë‚¸ hidden state ë²¡í„°ì¼ ê²ƒì…ë‹ˆë‹¤. ì¦‰, Aì–¸ì–´ì˜ ë¬¸ì¥ Xë¥¼ zë¼ëŠ” hidden stateë¡œ í•´ì„í•œ í›„ zë¥¼ ë‹¤ì‹œ B ì–¸ì–´ì˜ ë¬¸ì¥ Yë¡œ ì¬ìƒì„±í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ê·¸ëŸ¬ë¯€ë¡œ ì¸ì½”ë”ì—ì„œ í•„ìš”í•œ ê²ƒì€ ì¸ì½”ë”ì˜ ë§ˆì§€ë§‰ time stepì˜ hidden stateì…ë‹ˆë‹¤. ê·¸ë¦¬ê³  ì´ë¥¼ ë‘ë²ˆì§¸ RNNì¸ ë””ì½”ë”ì— ì „ë‹¬í•©ë‹ˆë‹¤.\n",
    "\n",
    "ë””ì½”ë”ëŠ” ì¸ì½”ë”ì˜ ë§ˆì§€ë§‰ time stepì˜ hidden stateë¥¼ ì „ë‹¬ ë°›ì•„ ìì‹ ì˜ ì´ˆê¸° hidden stateë¡œ í•˜ê³ , ì¶œë ¥ ë¬¸ì¥ì„ ìƒì„±í•´ë‚´ê¸° ì‹œì‘í•©ë‹ˆë‹¤. ì—¬ê¸°ì„œëŠ” íŠ¹ìˆ˜ ë¬¸ìë¥¼ ì‚¬ìš©í•´ì„œ ì¶œë ¥ ë¬¸ì¥ì˜ ì‹œì‘ê³¼ ì¢…ë£Œë¥¼ ì•Œë ¤ì£¼ì–´ì•¼ í•©ë‹ˆë‹¤. ë§¨ ìœ„ì˜ ê·¸ë¦¼ì—ì„œëŠ” _GOì™€ EOSê°€ ê°ê° ì‹œì‘ ë¬¸ìì™€ ì¢…ë£Œ ë¬¸ìì— í•´ë‹¹í•©ë‹ˆë‹¤. ë¬¸í—Œì— ë”°ë¼ì„œëŠ” SOSì™€ EOSë¼ê³ ë„ í•˜ëŠ”ë°, SOSëŠ” start of sequenceë¥¼ ì˜ë¯¸í•˜ë©°, EOSëŠ” end of sequenceë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤.\n",
    "\n",
    "### Conditional Language Model\n",
    "ë¬¸ì¥ ìƒì„±ê¸°(Text Generator) ëª¨ë¸ì„ ë§Œë“¤ì–´ ë³´ì•˜ë‹¤ë©´, ê·¸ëŸ¬í•œ ë¬¸ì¥ ìƒì„±ê¸°ëŠ” ì–¸ì–´ ëª¨ë¸(Language Model) ì„ êµ¬í˜„í•œ ê²ƒì´ë¼ëŠ” ê²ƒì„ ì•Œê³  ìˆì„ ê²ƒì…ë‹ˆë‹¤.\n",
    "\n",
    "ì–¸ì–´ ëª¨ë¸ì´ë€ n-1ê°œì˜ ë‹¨ì–´ ì‹œí€€ìŠ¤ $w_1, \\cdots, w_{n-1}$ê°€ ì£¼ì–´ì¡Œì„ ë•Œ, në²ˆì§¸ ë‹¨ì–´ $w_n$ìœ¼ë¡œ ë¬´ì—‡ì´ ì˜¬ì§€ë¥¼ ì˜ˆì¸¡í•˜ëŠ” í™•ë¥  ëª¨ë¸ì…ë‹ˆë‹¤. íŒŒë¼ë¯¸í„° $\\theta$ë¡œ ëª¨ë¸ë§í•˜ëŠ” ì–¸ì–´ ëª¨ë¸ì„ ë‹¤ìŒê³¼ ê°™ì´ í‘œí˜„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "$$\n",
    "P(w_n | w_1, ..., w_{n-1};\\theta )\n",
    "$$\n",
    "\n",
    "ìš°ë¦¬ê°€ ì•Œê³  ìˆëŠ” RNN ê³„ì—´ì˜ ëª¨ë¸ë“¤ì€ ì´ëŸ¬í•œ ì–¸ì–´ ëª¨ë¸ì„ êµ¬í˜„í•˜ê¸°ì— ì í•©í•œ ê²ƒë“¤ì…ë‹ˆë‹¤.\n",
    "\n",
    "ê·¸ëŸ°ë°, ì–¸ì–´ëª¨ë¸ì— ê¸°ë°˜í•œ ë¬¸ì¥ ìƒì„±ê¸°ê°€ ê°€ì§€ê³  ìˆëŠ” í•œê°€ì§€ ë¬¸ì œì ì´ ìˆìŠµë‹ˆë‹¤. ê·¸ê²ƒì€ ë°”ë¡œ, ì–´ë–¤ ë§ì„ ë§Œë“¤ê³  ì‹¶ì€ì§€ë¥¼ ì œì–´í•  ìˆ˜ ì—†ë‹¤ëŠ” ì ì…ë‹ˆë‹¤. RNN ëª¨ë¸ì€ í™•ë¥ ì ìœ¼ë¡œ ê·¸ ë‹¤ìŒ ë‚˜ì˜¬ ë‹¨ì–´ë“¤ì„ ìˆœì°¨ì ìœ¼ë¡œ ë§Œë“¤ì–´ ë‚˜ê°€ëŠ”ë°, ê·¸ê²ƒì„ ìƒí™©ì— ë§ê²Œ ì œì–´í•  ìˆ˜ ìˆë‹¤ë©´ ì•„ì£¼ ìœ ìš©í•  ê²ƒì…ë‹ˆë‹¤. ê·¸ë˜ì„œ ì‚¬ëŒë“¤ì€ ìœ„ ì–¸ì–´ëª¨ë¸ì„ í™•ì¥í•´ì„œ ì¡°ê±´ì  ì–¸ì–´ëª¨ë¸(Conditional Language Model)ì˜ ê°œë…ì„ ìƒê°í•˜ê²Œ ë©ë‹ˆë‹¤. ë§í•˜ìë©´ ì•„ë˜ì™€ ê°™ì€ í˜•íƒœê°€ ë  ê²ƒì…ë‹ˆë‹¤.\n",
    "\n",
    "$$\n",
    "P(w_n | w_1, ..., w_{n-1}, c;\\theta )\n",
    "$$\n",
    "\n",
    "ì´ ì‹ê³¼ ë‹¤ë¥´ê²Œ cë¼ëŠ” ê²ƒì´ í•˜ë‚˜ ë” ë¶™ì—ˆì§€ìš”? ì´ cë¥¼ ì´ìš©í•´ ê¸°ê³„ì—ê²Œ 'ì•„ë¬´ ë¬¸ì¥ì´ë‚˜ ë§Œë“¤ì§€ ë§ê³  cì— ì í•©í•œ ë¬¸ì¥ì„ ë§Œë“¤ì–´' ë¼ê³  ì£¼ë¬¸í•˜ê³  ì‹¶ì€ ê²ƒì…ë‹ˆë‹¤.\n",
    "\n",
    "ê¸°ê³„ë²ˆì—­ì´ì•¼ë§ë¡œ ê°€ì¥ ëŒ€í‘œì ì¸ Conditional Language Modelì˜ ì‚¬ë¡€ê°€ ë  ê²ƒì…ë‹ˆë‹¤. 'Xë¼ëŠ” ì˜ì–´ ë¬¸ì¥ì„ Yë¼ëŠ” í”„ë‘ìŠ¤ì–´ ë¬¸ì¥ìœ¼ë¡œ ë²ˆì—­í•´!' ë¼ëŠ” ê²ƒì€ ë°”ê¾¸ì–´ ë§í•˜ë©´, 'í”„ë‘ìŠ¤ì–´ ë¬¸ì¥ Yë¥¼ ë§Œë“¤ì–´ ë´, ë‹¨ ê·¸ ë¬¸ì¥ì€ ì˜ì–´ë¡œëŠ” Xë¼ëŠ” ëœ»ì´ì–´ì•¼ í•´.'ë¼ëŠ” ëœ»ì´ ë©ë‹ˆë‹¤. ê·¸ëŸ°ë° ì´ ì¡°ê±´ì„ ì–´ë–»ê²Œ ë¬¸ì¥ìƒì„±ê¸°ì— ë„£ì–´ ì¤„ê¹Œìš”? ê·¸ë ‡ìŠµë‹ˆë‹¤. ì´ ë¬¸ì¥ Xë¥¼ í•´ì„í•´ì„œ cë¡œ ë§Œë“œëŠ” ì¸ì½”ë”ë¥¼ ë˜ë‹¤ë¥¸ RNNìœ¼ë¡œ ë§Œë“œëŠ” ê²ƒì…ë‹ˆë‹¤. ê·¸ë ‡ê²Œ ë§Œë“  cë¥¼ ë‹¤ì‹œ ë¬¸ì¥ìƒì„±ê¸°ì¸ ë””ì½”ë” RNNì— ì…ë ¥ìœ¼ë¡œ ë„£ì–´ì£¼ëŠ” ëª¨ë¸ì„ ë§Œë“¤ì–´ ë‚¸ ê²ƒì´ ë°”ë¡œ ì˜¤ëŠ˜ ë‹¤ë£¨ê²Œ ë  seq2seqì¸ ê²ƒì…ë‹ˆë‹¤."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## êµì‚¬ ê°•ìš”(teacher forcing)\n",
    "\n",
    "seq2seqëŠ” í›ˆë ¨ ê³¼ì •ê³¼ í…ŒìŠ¤íŠ¸ ê³¼ì •ì—ì„œì˜ ë™ì‘ ë°©ì‹ì´ ë‹¤ë¥´ë‹¤ëŠ” íŠ¹ì§•ì´ ìˆìŠµë‹ˆë‹¤. ì´ì „ ìŠ¤í…ì˜ ê·¸ë¦¼ì„ ë³´ë©´ ë””ì½”ë” RNNì€ ì´ì „ time stepì˜ ì¶œë ¥ì„ í˜„ì¬ time stepì˜ ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©í•œë‹¤ëŠ” íŠ¹ì§•ì„ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤. ê·¸ëŸ°ë° ì´ëŠ” í…ŒìŠ¤íŠ¸ ê³¼ì •ì—ì„œì˜ ì´ì•¼ê¸°ì´ê³ , í›ˆë ¨ ê³¼ì •ì€ ì¡°ê¸ˆ ë‹¤ë¥¸ ë°©ì‹ì„ ì‚¬ìš©í•©ë‹ˆë‹¤. ê·¸ ì´ìœ ëŠ” í›ˆë ¨ ê³¼ì •ì—ì„œ ì´ì „ time stepì´ ì˜ëª»ëœ ì˜ˆì¸¡ì„ í•œë‹¤ë©´ ì´ë¥¼ ì…ë ¥ìœ¼ë¡œ í•œ í˜„ì¬ time stepì˜ ì˜ˆì¸¡ë„ ì˜ëª»ë  ìˆ˜ ìˆê¸° ë•Œë¬¸ì…ë‹ˆë‹¤. ì´ëŸ° ìƒí™©ì´ ë°˜ë³µë˜ë©´ í›ˆë ¨ ì‹œê°„ì´ êµ‰ì¥íˆ ëŠ˜ì–´ë‚˜ê²Œ ë©ë‹ˆë‹¤.\n",
    "\n",
    "![image](https://d3s0tskafalll9.cloudfront.net/media/original_images/E-15-6.teacher_forcing.png)\n",
    "\n",
    "í›ˆë ¨ ê³¼ì •ì—ì„œëŠ” ì‹¤ì œ ì •ë‹µ ì‹œí€€ìŠ¤ë¥¼ ì•Œê³  ìˆëŠ” ìƒí™©ì´ë¯€ë¡œ ì´ì „ time stepì˜ ì˜ˆì¸¡ê°’ì„ í˜„ì¬ time stepì˜ ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼ ì´ì „ time stepì˜ ì‹¤ì œê°’ìœ¼ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ ì‘ì—…ì„ êµì‚¬ ê°•ìš”(teacher forcing)ì´ë¼ê³  í•©ë‹ˆë‹¤. ì´ ê¸°ë²•ì€ seq2seq ë¿ ì•„ë‹ˆë¼ sequence ë°ì´í„°ì˜ ìƒì„±ëª¨ë¸ì—ì„œ ì¼ë°˜ì ìœ¼ë¡œ ì‚¬ìš©ë˜ëŠ” ê¸°ë²•ì´ê¸°ë„ í•©ë‹ˆë‹¤. ë¬¼ë¡ , ì´ëŠ” ëª¨ë¸ì´ í›ˆë ¨ ë°ì´í„° ì™¸ì˜ ê²°ê³¼ë¥¼ ìƒì„±í•´ë‚´ëŠ” ëŠ¥ë ¥ì„ ê¸°ë¥´ëŠ”ë°ì— ì¡°ê¸ˆ ë°©í•´ê°€ ë  ìˆ˜ ìˆë‹¤ëŠ” ë‹¨ì ë„ ì¡´ì¬í•©ë‹ˆë‹¤."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ë‹¨ì–´ ìˆ˜ì¤€ vs ë¬¸ì ìˆ˜ì¤€\n",
    "seq2seqëŠ” ë‹¨ì–´ ìˆ˜ì¤€(word level) ë˜ëŠ” ë¬¸ì ìˆ˜ì¤€(character level) ë‘ ê°€ì§€ ë°©ë²•ìœ¼ë¡œ êµ¬í˜„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë‹¨ì–´ ìˆ˜ì¤€ì´ë¼ê³  í•¨ì€ ê° RNNì˜ time stepì˜ ì…ì¶œë ¥ ë‹¨ìœ„ê°€ ë‹¨ì–´ ìˆ˜ì¤€ì´ë¼ëŠ” ì˜ë¯¸ì´ê³ , ë¬¸ì ìˆ˜ì¤€ì´ë¼ í•¨ì€ RNNì˜ time stepì˜ ì…ì¶œë ¥ ë‹¨ìœ„ê°€ ë¬¸ì ìˆ˜ì¤€, ì˜ì–´ì—ì„œëŠ” ì•ŒíŒŒë²³ ë‹¨ìœ„ì…ë‹ˆë‹¤.\n",
    "\n",
    "ì‹¤ì œ êµ¬í˜„ ìì²´ëŠ” ë¬¸ì ìˆ˜ì¤€ì´ ì¢€ ë” ì‰¬ìš´ë°, ê·¸ ì´ìœ ëŠ” ë‹¨ì–´ ìˆ˜ì¤€ seq2seqì˜ ê²½ìš° ë§¤ time stepì—ì„œ ë””ì½”ë” RNNì´ ì¶œë ¥ì„ ê²°ì •í•  ë•Œ, í›ˆë ¨ ë°ì´í„°ì— ìˆëŠ” ì „ì²´ ë‹¨ì–´ ì§‘í•©ì˜ ìˆ˜ê°€ 30ë§Œê°œë¼ë©´ 30ë§Œê°œ ì¤‘ í•˜ë‚˜ë¥¼ ì„ íƒí•´ì•¼ í•˜ë¯€ë¡œ ì¶œë ¥ì¸µì˜ í¬ê¸°ê°€ ë¬´ë ¤ 30ë§Œì´ì–´ì•¼ í•©ë‹ˆë‹¤.\n",
    "\n",
    "í•˜ì§€ë§Œ ë¬¸ì ìˆ˜ì¤€ìœ¼ë¡œ êµ¬í˜„í•˜ë©´ ì˜ë¬¸ì ì•ŒíŒŒë²³ì€ 26ê°œì— ë¶ˆê³¼í•˜ë¯€ë¡œ ì¶œë ¥ì¸µì˜ í¬ê¸°ê°€ êµ‰ì¥íˆ ì‘ì•„ì§‘ë‹ˆë‹¤. ì—¬ê¸°ì— ëŒ€, ì†Œë¬¸ìë¥¼ êµ¬ë¶„í•˜ì§€ ì•Šê³  íŠ¹ìˆ˜ë¬¸ìë¥¼ í¬í•¨í•œë‹¤ê³  í•˜ë”ë¼ë„ ì¶œë ¥ì¸µì˜ í¬ê¸°ëŠ” 100ì„ ë„˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\n",
    "\n",
    "ê·¸ë ‡ë‹¤ë©´ ë‹¨ì–´ ìˆ˜ì¤€ì˜ ë²ˆì—­ê³¼ ë¬¸ì ìˆ˜ì¤€ì˜ ë²ˆì—­ ë‘˜ ì¤‘ ì–´ëŠ ìª½ì´ ë” ìœ ë¦¬í• ê¹Œìš”?\n",
    "\n",
    "ë‘ ë°©ë²•ì—ëŠ” ì¥ë‹¨ì ì´ ìˆìŠµë‹ˆë‹¤. ê·¸ë¦¬ê³  ê·¸ ì¥ë‹¨ì ì€ ì„œë¡œ trade-off ê´€ê³„ì´ê¸°ë„ í•©ë‹ˆë‹¤.\n",
    "\n",
    "ë‹¨ì–´ ìˆ˜ì¤€ì˜ ë²ˆì—­ì„ ìœ„í•´ì„œ ì‚¬ì „ì„ êµ¬ì¶•í•œë‹¤ê³  ìƒê°í•´ ë´…ì‹œë‹¤. ê°€ì¥ ê·¹ë‹¨ì ì¸ ê²½ìš°ì— í•´ë‹¹í•˜ëŠ” í•œêµ­ì–´ì˜ ì˜ˆë¥¼ ë“¤ì–´ ë´…ì‹œë‹¤.\n",
    "\n",
    ">ë¨¹ë‹¤, ë¨¹ëŠ”ë‹¤, ë¨¹ê³ , ë¨¹ì§€, ë¨¹ì„ê¹Œ.....\n",
    "\n",
    "'ë¨¹ë‹¤'ë¼ëŠ” ë‹¨ì–´ í•˜ë‚˜ì— ì´ë ‡ê²Œ ë§ì€ ë³€ì¢…ì´ ìˆê³ , ì˜ë¯¸ê°€ ì•„ì£¼ ì•½ê°„ì”©ì€ ë‹¤ë¦…ë‹ˆë‹¤. ì´ë ‡ê²Œ ë”°ì§€ë©´ ì—„ì²­ë‚˜ê²Œ í° ë‹¨ì–´ ì‚¬ì „ì´ í•„ìš”í•˜ê²Œ ë©ë‹ˆë‹¤. ì˜ì–´ì—ë„ ì´ëŸ° ë¬¸ì œê°€ ìˆê² ì§€ë§Œ í•œêµ­ì–´ì— ë¹„í•˜ë©´ğŸ˜ ê·¸ ë³€í™”ê°€ ê·¸ë¦¬ ì‹¬í•˜ì§€ëŠ” ì•ŠìŠµë‹ˆë‹¤. ë‹¨ì–´ ìˆ˜ì¤€ì˜ ì ‘ê·¼ì—ì„œ ë˜ í•˜ë‚˜ì˜ ì–´ë ¤ì›€ì€ ë„ì–´ì“°ê¸°ì˜ ë¬¸ì œì…ë‹ˆë‹¤. íŠ¹íˆ ë„ì–´ì“°ê¸°ê°€ ë§ì´ ìƒëµë˜ëŠ” í•œêµ­ì–´, ì¼ë³¸ì–´ ê°™ì€ ì–¸ì–´ë“¤ì˜ ê²½ìš° ì´ëŸ¬í•œ ì „ì²˜ë¦¬ê°€ í° ì–´ë ¤ì›€ì˜ ì›ì¸ì´ ë©ë‹ˆë‹¤.\n",
    "\n",
    "ê·¸ë ‡ë‹¤ë©´ ë¬¸ì ìˆ˜ì¤€ìœ¼ë¡œ ë²ˆì—­í•˜ë©´ ì´ëŸ° ë¬¸ì œê°€ ì—†ì´ ì•„ì£¼ ê¹”ë”í•˜ê²Œ í•´ê²°ë˜ê² ì£ ? ê·¸ëŸ¬ë‚˜ ë‹¨ì–´ë¥¼ ë¬¸ì ìˆ˜ì¤€ìœ¼ë¡œ ìª¼ê° ë‹¤ëŠ” ê²ƒì€ ë‹¨ì–´ ì•ˆì— ë‚´ì¬ëœ ì •ë³´ê°€ ì†Œì‹¤ëœë‹¤ëŠ” ê²ƒì„ ì˜ë¯¸í•©ë‹ˆë‹¤. ì¦‰, ê¸°ê³„ê°€ ë°ì´í„°ë¥¼ í†µí•´ ê¸€ìê°€ ë‹¨ì–´ë¥¼ ì´ë£¨ëŠ” íŒ¨í„´ê¹Œì§€ í•™ìŠµí•´ ë‚´ì•¼ í•œë‹¤ëŠ” ê²ƒì…ë‹ˆë‹¤. ê·¸ë˜ì„œ ì¶©ë¶„í•œ ë°ì´í„°ê°€ í™•ë³´ë˜ì§€ ì•Šì•˜ë‹¤ë©´ ì¼ë°˜ì ìœ¼ë¡œ ë¬¸ì ìˆ˜ì¤€ì˜ ë²ˆì—­ì´ ë‹¨ì–´ ìˆ˜ì¤€ì˜ ë²ˆì—­ë³´ë‹¤ í’ˆì§ˆì´ ë–¨ì–´ì§‘ë‹ˆë‹¤.\n",
    "\n",
    "ìµœì‹  ìì—°ì–´ì²˜ë¦¬ì˜ íë¦„ì€ ë‹¨ì–´ ìˆ˜ì¤€ì´ë‚˜ ë¬¸ì ìˆ˜ì¤€ì˜ ë²ˆì—­ì´ ì•„ë‹Œ, ê·¸ ì‚¬ì´ì˜ subword ê¸°ë°˜ì˜ ë²ˆì—­ì´ ì£¼ë¥¼ ì´ë£¨ê³  ìˆìŠµë‹ˆë‹¤. ì´ì— ëŒ€í•´ì„œëŠ” ì‹¬í™” ê³¼ì •ì—ì„œ ìì„¸íˆ ë‹¤ë£¨ê²Œ ë  ê²ƒì…ë‹ˆë‹¤.\n",
    "\n",
    "---\n",
    "\n",
    "ì´ë²ˆ ì±•í„°ì—ì„œëŠ” ì „ì²˜ë¦¬ì™€ í›ˆë ¨ ì‹œê°„ì„ ê³ ë ¤í•˜ì—¬ ë¬¸ì ìˆ˜ì¤€ìœ¼ë¡œ êµ¬ì¶•í•´ë³´ê² ìŠµë‹ˆë‹¤. ê·¸ë¦¬ê³  ì¼ë‹¨ ë¬¸ì ìˆ˜ì¤€ ë²ˆì—­ê¸°ë¥¼ êµ¬ì¶•í•˜ê³ ë‚˜ë©´ ë‹¨ì–´ ìˆ˜ì¤€ ëª¨ë¸ë¡œ ë³€í™˜í•˜ëŠ” ê²ƒì€ êµ‰ì¥íˆ ì‰½ê¸° ë•Œë¬¸ì— ì´ëŠ” ì¶”í›„ ë…ìë“¤ì˜ ì—°ìŠµìœ¼ë¡œ ë‚¨ê²¨ë‘ê² ìŠµë‹ˆë‹¤.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ë²ˆì—­ê¸° ë§Œë“¤ê¸° (1) ë°ì´í„° ì „ì²˜ë¦¬\n",
    "ì´ë²ˆ ì±•í„°ì—ì„œ ì‚¬ìš©í•  ë°ì´í„°ëŠ” https://www.manythings.org/anki/ì—ì„œ ë‹¤ìš´ë¡œë“œ í•˜ê² ìŠµë‹ˆë‹¤. ì—¬ê¸°ì„œëŠ” í”„ë‘ìŠ¤ì–´ì™€ ì˜ì–´ì˜ ë³‘ë ¬ ì½”í¼ìŠ¤ì¸ fra-eng.zipì„ ë‹¤ìš´ë°›ì•„ ì‚¬ìš©í•©ë‹ˆë‹¤. ê°€ìš´ë° ì¯¤ì— ìˆìœ¼ë‹ˆ ì˜ ì°¾ì•„ë³´ì‹œê³  ì•„ë‹ˆë©´ ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ ë‹¤ìš´ë¡œë“œë¥¼ ë°›ì•„ë„ ë©ë‹ˆë‹¤.\n",
    "```\n",
    "$ mkdir -p ~/aiffel/translator_seq2seq/data\n",
    "$ mkdir -p ~/aiffel/translator_seq2seq/models\n",
    "$ wget https://www.manythings.org/anki/fra-eng.zip\n",
    "$ mv fra-eng.zip  ~/aiffel/translator_seq2seq/data\n",
    "$ cd ~/aiffel/translator_seq2seq/data && unzip fra-eng.zip\n",
    "```\n",
    "ì´ íŒŒì¼ì˜ ì••ì¶•ì„ í’€ë©´ fra.txtë¼ëŠ” íŒŒì¼ì´ ì¡´ì¬í•˜ëŠ”ë° ì´ íŒŒì¼ì´ ìš°ë¦¬ê°€ ì‚¬ìš©í•  í›ˆë ¨ ë°ì´í„°ì…ë‹ˆë‹¤.\n",
    "\n",
    "ìš°ì„  í•„ìš”í•œ ë„êµ¬ë“¤ì„ ì„í¬íŠ¸í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python 3.9.13ì—ì„œ ì„¤ì¹˜ ê°€ëŠ¥\n",
    "# ê°€ìƒí™˜ê²½ ì§„ì…\n",
    "# $ python -m pip install -U pip\n",
    "# $ python -m pip install tensorflow-macos\n",
    "# $ python -m pip install tensorflow-metal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "í•´ë‹¹ íŒŒì¼ì„ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ì½ì–´ì˜µë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì „ì²´ ìƒ˜í”Œì˜ ìˆ˜ : 197463\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>fra</th>\n",
       "      <th>cc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7549</th>\n",
       "      <td>I saw a plane.</td>\n",
       "      <td>J'ai vu un avion.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95280</th>\n",
       "      <td>I just got home from school.</td>\n",
       "      <td>Je viens de rentrer de l'Ã©cole.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12592</th>\n",
       "      <td>We're not deaf.</td>\n",
       "      <td>Nous ne sommes pas sourds.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87779</th>\n",
       "      <td>I mowed the lawn last week.</td>\n",
       "      <td>J'ai tondu la pelouse la semaine derniÃ¨re.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135283</th>\n",
       "      <td>I didn't answer a single question.</td>\n",
       "      <td>Je n'ai rÃ©pondu Ã  aucune question.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       eng  \\\n",
       "7549                        I saw a plane.   \n",
       "95280         I just got home from school.   \n",
       "12592                      We're not deaf.   \n",
       "87779          I mowed the lawn last week.   \n",
       "135283  I didn't answer a single question.   \n",
       "\n",
       "                                               fra  \\\n",
       "7549                             J'ai vu un avion.   \n",
       "95280              Je viens de rentrer de l'Ã©cole.   \n",
       "12592                   Nous ne sommes pas sourds.   \n",
       "87779   J'ai tondu la pelouse la semaine derniÃ¨re.   \n",
       "135283          Je n'ai rÃ©pondu Ã  aucune question.   \n",
       "\n",
       "                                                       cc  \n",
       "7549    CC-BY 2.0 (France) Attribution: tatoeba.org #3...  \n",
       "95280   CC-BY 2.0 (France) Attribution: tatoeba.org #3...  \n",
       "12592   CC-BY 2.0 (France) Attribution: tatoeba.org #9...  \n",
       "87779   CC-BY 2.0 (France) Attribution: tatoeba.org #6...  \n",
       "135283  CC-BY 2.0 (France) Attribution: tatoeba.org #2...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "file_path = './data/230113/fra.txt'\n",
    "lines = pd.read_csv(file_path, names=['eng', 'fra', 'cc'], sep='\\t')\n",
    "print('ì „ì²´ ìƒ˜í”Œì˜ ìˆ˜ :',len(lines))\n",
    "lines.sample(5) #ìƒ˜í”Œ 5ê°œ ì¶œë ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>fra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31531</th>\n",
       "      <td>Send me some money.</td>\n",
       "      <td>Envoie-moi de l'argent.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1611</th>\n",
       "      <td>What's up?</td>\n",
       "      <td>Comment vas-tu ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11613</th>\n",
       "      <td>Seal the doors.</td>\n",
       "      <td>Scellez la porte !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20801</th>\n",
       "      <td>They're harmless.</td>\n",
       "      <td>Ils ne sont pas dangereux.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31276</th>\n",
       "      <td>Look at it closely.</td>\n",
       "      <td>Regarde-la attentivement.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       eng                         fra\n",
       "31531  Send me some money.     Envoie-moi de l'argent.\n",
       "1611            What's up?            Comment vas-tu ?\n",
       "11613      Seal the doors.          Scellez la porte !\n",
       "20801    They're harmless.  Ils ne sont pas dangereux.\n",
       "31276  Look at it closely.   Regarde-la attentivement."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = lines[['eng', 'fra']][:50000] # 5ë§Œê°œ ìƒ˜í”Œ ì‚¬ìš©\n",
    "lines.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì „ì²´ ìƒ˜í”Œì˜ ìˆ˜ : 50000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>fra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40817</th>\n",
       "      <td>Can you do it faster?</td>\n",
       "      <td>\\t Arrives-tu Ã  le faire plus vite ? \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8909</th>\n",
       "      <td>Tom looks sad.</td>\n",
       "      <td>\\t Tom a l'air triste. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37400</th>\n",
       "      <td>It's very hot today.</td>\n",
       "      <td>\\t Aujourd'hui, il fait trÃ¨s chaud. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44661</th>\n",
       "      <td>See you all tomorrow.</td>\n",
       "      <td>\\t Je vous verrai toutes demain. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8279</th>\n",
       "      <td>Memorize this.</td>\n",
       "      <td>\\t MÃ©morisez ceci. \\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         eng                                      fra\n",
       "40817  Can you do it faster?  \\t Arrives-tu Ã  le faire plus vite ? \\n\n",
       "8909          Tom looks sad.                \\t Tom a l'air triste. \\n\n",
       "37400   It's very hot today.   \\t Aujourd'hui, il fait trÃ¨s chaud. \\n\n",
       "44661  See you all tomorrow.      \\t Je vous verrai toutes demain. \\n\n",
       "8279          Memorize this.                    \\t MÃ©morisez ceci. \\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ì‹œì‘ í† í°ê³¼ ì¢…ë£Œ í† í° ì¶”ê°€\n",
    "sos_token = '\\t'\n",
    "eos_token = '\\n'\n",
    "lines.fra = lines.fra.apply(lambda x : '\\t '+ x + ' \\n')\n",
    "print('ì „ì²´ ìƒ˜í”Œì˜ ìˆ˜ :',len(lines))\n",
    "lines.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì´ì œ ë‹¨ì–´ì¥(vocabulary)ì„ ë§Œë“¤ê³ , ê° ë‹¨ì–´ì— ë¶€ì—¬ëœ ê³ ìœ í•œ ì •ìˆ˜ë¡œ í…ìŠ¤íŠ¸ ì‹œí€€ìŠ¤ë¥¼ ì •ìˆ˜ ì‹œí€€ìŠ¤ë¡œ ë³€í™˜í•˜ëŠ” ì •ìˆ˜ ì¸ì½”ë”© ê³¼ì •ì„ ê±°ì¹˜ê² ìŠµë‹ˆë‹¤. ì´ë•Œ ì˜ì–´ì™€ í”„ë‘ìŠ¤ì–´ëŠ” ì‚¬ìš©í•˜ëŠ” ì–¸ì–´ê°€ ë‹¤ë¥´ë¯€ë¡œ ë‹¨ì–´ì¥ì„ ë³„ë„ë¡œ ë§Œë“¤ì–´ì¤ë‹ˆë‹¤. ê·¸ë¦¬ê³  ì •ìƒì ìœ¼ë¡œ ì •ìˆ˜ ì‹œí€€ìŠ¤ë¡œ ë³€í™˜ë˜ì—ˆëŠ”ì§€ 3ê°œì˜ í–‰ì„ ì¶œë ¥í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[19, 3, 8], [19, 3, 8], [19, 3, 8]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_tokenizer = Tokenizer(char_level=True)   # ë¬¸ì ë‹¨ìœ„ë¡œ Tokenizerë¥¼ ìƒì„±í•©ë‹ˆë‹¤. \n",
    "eng_tokenizer.fit_on_texts(lines.eng)               # 50000ê°œì˜ í–‰ì„ ê°€ì§„ engì˜ ê° í–‰ì— í† í°í™”ë¥¼ ìˆ˜í–‰\n",
    "input_text = eng_tokenizer.texts_to_sequences(lines.eng)    # ë‹¨ì–´ë¥¼ ìˆ«ìê°’ ì¸ë±ìŠ¤ë¡œ ë³€í™˜í•˜ì—¬ ì €ì¥\n",
    "input_text[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[10, 1, 19, 5, 1, 31, 1, 11],\n",
       " [10, 1, 15, 5, 12, 16, 29, 2, 14, 1, 11],\n",
       " [10, 1, 2, 7, 1, 12, 9, 8, 4, 2, 1, 31, 1, 11]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fra_tokenizer = Tokenizer(char_level=True)   # ë¬¸ì ë‹¨ìœ„ë¡œ Tokenizerë¥¼ ìƒì„±í•©ë‹ˆë‹¤. \n",
    "fra_tokenizer.fit_on_texts(lines.fra)                 # 50000ê°œì˜ í–‰ì„ ê°€ì§„ fraì˜ ê° í–‰ì— í† í°í™”ë¥¼ ìˆ˜í–‰\n",
    "target_text = fra_tokenizer.texts_to_sequences(lines.fra)     # ë‹¨ì–´ë¥¼ ìˆ«ìê°’ ì¸ë±ìŠ¤ë¡œ ë³€í™˜í•˜ì—¬ ì €ì¥\n",
    "target_text[:3]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ë‹¨ì–´ì¥ì˜ í¬ê¸°ë¥¼ ë³€ìˆ˜ë¡œ ì €ì¥í•´ì¤ë‹ˆë‹¤. 0ë²ˆ í† í°ì„ ê³ ë ¤í•˜ì—¬ +1ì„ í•˜ê³  ì €ì¥í•´ì¤ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì˜ì–´ ë‹¨ì–´ì¥ì˜ í¬ê¸° : 53\n",
      "í”„ë‘ìŠ¤ì–´ ë‹¨ì–´ì¥ì˜ í¬ê¸° : 73\n"
     ]
    }
   ],
   "source": [
    "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
    "fra_vocab_size = len(fra_tokenizer.word_index) + 1\n",
    "print('ì˜ì–´ ë‹¨ì–´ì¥ì˜ í¬ê¸° :', eng_vocab_size)\n",
    "print('í”„ë‘ìŠ¤ì–´ ë‹¨ì–´ì¥ì˜ í¬ê¸° :', fra_vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì´ì œ ì˜ì–´ ë°ì´í„°ì™€ í”„ë‘ìŠ¤ì–´ ë°ì´í„°ì˜ ìµœëŒ€ ê¸¸ì´ë¥¼ ê°ê° êµ¬í•´ë³´ê² ìŠµë‹ˆë‹¤. ì´ëŠ” íŒ¨ë”©(<pad>)ì„ ìœ„í•¨ì…ë‹ˆë‹¤. ëª¨ë¸ì— ì…ë ¥ë  ì˜ì–´, í”„ë‘ìŠ¤ì–´ ì‹œí€€ìŠ¤ì˜ ê¸¸ì´ê°€ ì¼ì •í•´ì•¼ í•˜ë¯€ë¡œ, ìµœëŒ€ ê¸¸ì´ë¡œ ë§ì¶”ê³  ë‚¨ëŠ” ì‹œí€€ìŠ¤ ë’·ë¶€ë¶„ì„ íŒ¨ë”©ìœ¼ë¡œ ì±„ìš°ê²Œ ë©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì˜ì–´ ì‹œí€€ìŠ¤ì˜ ìµœëŒ€ ê¸¸ì´ 22\n",
      "í”„ë‘ìŠ¤ì–´ ì‹œí€€ìŠ¤ì˜ ìµœëŒ€ ê¸¸ì´ 76\n",
      "ì „ì²´ ìƒ˜í”Œì˜ ìˆ˜ : 50000\n",
      "ì˜ì–´ ë‹¨ì–´ì¥ì˜ í¬ê¸° : 53\n",
      "í”„ë‘ìŠ¤ì–´ ë‹¨ì–´ì¥ì˜ í¬ê¸° : 73\n",
      "ì˜ì–´ ì‹œí€€ìŠ¤ì˜ ìµœëŒ€ ê¸¸ì´ 22\n",
      "í”„ë‘ìŠ¤ì–´ ì‹œí€€ìŠ¤ì˜ ìµœëŒ€ ê¸¸ì´ 76\n"
     ]
    }
   ],
   "source": [
    "max_eng_seq_len = max([len(line) for line in input_text])\n",
    "max_fra_seq_len = max([len(line) for line in target_text])\n",
    "print('ì˜ì–´ ì‹œí€€ìŠ¤ì˜ ìµœëŒ€ ê¸¸ì´', max_eng_seq_len)\n",
    "print('í”„ë‘ìŠ¤ì–´ ì‹œí€€ìŠ¤ì˜ ìµœëŒ€ ê¸¸ì´', max_fra_seq_len)\n",
    "print('ì „ì²´ ìƒ˜í”Œì˜ ìˆ˜ :',len(lines))\n",
    "print('ì˜ì–´ ë‹¨ì–´ì¥ì˜ í¬ê¸° :', eng_vocab_size)\n",
    "print('í”„ë‘ìŠ¤ì–´ ë‹¨ì–´ì¥ì˜ í¬ê¸° :', fra_vocab_size)\n",
    "print('ì˜ì–´ ì‹œí€€ìŠ¤ì˜ ìµœëŒ€ ê¸¸ì´', max_eng_seq_len)\n",
    "print('í”„ë‘ìŠ¤ì–´ ì‹œí€€ìŠ¤ì˜ ìµœëŒ€ ê¸¸ì´', max_fra_seq_len)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì¸ì½”ë”ì˜ ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©ë˜ëŠ” ì˜ì–´ ì‹œí€€ìŠ¤ì™€ ë‹¬ë¦¬, í”„ë‘ìŠ¤ì–´ ì‹œí€€ìŠ¤ëŠ” 2ê°€ì§€ ë²„ì „ìœ¼ë¡œ ë‚˜ëˆ„ì–´ ì¤€ë¹„í•´ì•¼ í•©ë‹ˆë‹¤. í•˜ë‚˜ëŠ” ë””ì½”ë”ì˜ ì¶œë ¥ê³¼ ë¹„êµí•´ì•¼ í•  ì •ë‹µ ë°ì´í„°ë¡œ ì‚¬ìš©í•´ì•¼ í•  ì›ë˜ ëª©ì ì— ë”°ë¥¸ ê²ƒì…ë‹ˆë‹¤. ê·¸ë¦¬ê³  ë‹¤ë¥¸ í•˜ë‚˜ëŠ” ì´ì „ ìŠ¤í…ì—ì„œ ì–¸ê¸‰í–ˆë˜ êµì‚¬ ê°•ìš”(Teacher forcing)ì„ ìœ„í•´ ë””ì½”ë”ì˜ ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©í•˜ê¸° ìœ„í•œ ê²ƒì…ë‹ˆë‹¤.\n",
    "\n",
    "ê°™ì€ ë¬¸ì¥ì„ êµ³ì´ 2ê°€ì§€ ë²„ì „ìœ¼ë¡œ ë‚˜ëˆ„ëŠ” ì´ìœ ëŠ”, ë””ì½”ë”ì˜ ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©í•  ì‹œí€€ìŠ¤ëŠ” \\<eos\\> í† í°ì´ í•„ìš”ê°€ ì—†ê³ , ë””ì½”ë”ì˜ ì¶œë ¥ê³¼ ë¹„êµí•  ì‹œí€€ìŠ¤ëŠ” \\<sos\\>ê°€ í•„ìš”ê°€ ì—†ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤. ê°€ë ¹, ì˜ì–´ë¡œ 'I am a person'ì´ë¼ëŠ” ë¬¸ì¥ì„ í”„ë‘ìŠ¤ì–´ 'Je suis une personne'ë¡œ ë²ˆì—­í•˜ëŠ” ë²ˆì—­ê¸°ë¥¼ ë§Œë“ ë‹¤ê³  í•´ë´…ì‹œë‹¤. í›ˆë ¨ ê³¼ì •ì—ì„œ ë””ì½”ë”ëŠ” '\\<sos\\> Je suis une personne'ë¥¼ ì…ë ¥ë°›ì•„ì„œ 'Je suis une personne \\<eos\\>'ë¥¼ ì˜ˆì¸¡í•˜ë„ë¡ í›ˆë ¨ë˜ë¯€ë¡œ, ì´ëŸ° ë°©ì‹ìœ¼ë¡œ ìƒì„±ëœ ë‘ê°€ì§€ ë²„ì „ì˜ ì‹œí€€ìŠ¤ë¥¼ ì¤€ë¹„í•´ì•¼ í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = input_text\n",
    "\n",
    "# ì¢…ë£Œ í† í° ì œê±°\n",
    "decoder_input = [[ char for char in line if char != fra_tokenizer.word_index[eos_token] ] for line in target_text] \n",
    "\n",
    "# ì‹œì‘ í† í° ì œê±°\n",
    "decoder_target = [[ char for char in line if char != fra_tokenizer.word_index[sos_token] ] for line in target_text]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ë””ì½”ë”ì˜ ì…ë ¥ê³¼ ì¶œë ¥ì„ ê°ê° ì¶œë ¥í•´ë´…ì‹œë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10, 1, 19, 5, 1, 31, 1], [10, 1, 15, 5, 12, 16, 29, 2, 14, 1], [10, 1, 2, 7, 1, 12, 9, 8, 4, 2, 1, 31, 1]]\n",
      "[[1, 19, 5, 1, 31, 1, 11], [1, 15, 5, 12, 16, 29, 2, 14, 1, 11], [1, 2, 7, 1, 12, 9, 8, 4, 2, 1, 31, 1, 11]]\n"
     ]
    }
   ],
   "source": [
    "print(decoder_input[:3])\n",
    "print(decoder_target[:3])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ë””ì½”ë”ì˜ ì…ë ¥ì˜ ê²½ìš°ì—ëŠ” ìˆ«ì 11(\\<eos\\> í† í°)ê°€ ì œê±°ë˜ì—ˆê³ , ë””ì½”ë”ì˜ ì¶œë ¥ì˜ ê²½ìš°ì—ëŠ” ìˆ«ì 10(\\<sos\\> í† í°)ì´ ì œê±°ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ì œ íŒ¨ë”©ì„ ì§„í–‰í•©ë‹ˆë‹¤. íŒ¨ë”©ì„ ì§„í–‰í•˜ë©´ ëª¨ë“  ìƒ˜í”Œë“¤ì˜ ê¸¸ì´ê°€ ì •í•´ì¤€ ê¸¸ì´ë¡œ ë™ì¼í•˜ê²Œ ë³€í™˜ë©ë‹ˆë‹¤. ì—¬ê¸°ì„œëŠ” ì•„ê¹Œ ì €ì¥í•´ë‘ì—ˆë˜ ê°€ì¥ ê¸´ ìƒ˜í”Œì˜ ê¸¸ì´ì¸ max_eng_seq_len, max_fra_seq_lenë¥¼ ê°ê° ì‚¬ìš©í•˜ì˜€ìŠµë‹ˆë‹¤.\n",
    "\n",
    "ì´ë ‡ê²Œ ë˜ë©´ ì˜ì–´ ë°ì´í„°ì˜ ëª¨ë“  ìƒ˜í”Œë“¤ì€ max_eng_seq_lenì˜ ê¸¸ì´ë¥¼ ê°€ì§€ê³ , í”„ë‘ìŠ¤ì–´ì˜ ëª¨ë“  ìƒ˜í”Œë“¤ì€ max_fra_seq_lenì˜ ê¸¸ì´ê°€ ë˜ê² ì£ ?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì˜ì–´ ë°ì´í„°ì˜ í¬ê¸°(shape) : (50000, 22)\n",
      "í”„ë‘ìŠ¤ì–´ ì…ë ¥ë°ì´í„°ì˜ í¬ê¸°(shape) : (50000, 76)\n",
      "í”„ë‘ìŠ¤ì–´ ì¶œë ¥ë°ì´í„°ì˜ í¬ê¸°(shape) : (50000, 76)\n"
     ]
    }
   ],
   "source": [
    "encoder_input = pad_sequences(encoder_input, maxlen = max_eng_seq_len, padding='post')\n",
    "decoder_input = pad_sequences(decoder_input, maxlen = max_fra_seq_len, padding='post')\n",
    "decoder_target = pad_sequences(decoder_target, maxlen = max_fra_seq_len, padding='post')\n",
    "print('ì˜ì–´ ë°ì´í„°ì˜ í¬ê¸°(shape) :',np.shape(encoder_input))\n",
    "print('í”„ë‘ìŠ¤ì–´ ì…ë ¥ë°ì´í„°ì˜ í¬ê¸°(shape) :',np.shape(decoder_input))\n",
    "print('í”„ë‘ìŠ¤ì–´ ì¶œë ¥ë°ì´í„°ì˜ í¬ê¸°(shape) :',np.shape(decoder_target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ëª¨ë“  ìƒ˜í”Œë“¤ì˜ ê¸¸ì´ê°€ ë™ì¼í•˜ê²Œ ë³€í™˜ëœ ê²ƒì„ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ëª¨ë“  ìƒ˜í”Œë“¤ì˜ ê¸¸ì´ê°€ ë™ì¼í•˜ê²Œ ë³€í™˜ë˜ëŠ” ê³¼ì •ì—ì„œ ì •í•´ì¤€ ê¸¸ì´ë³´ë‹¤ ì§§ì€ ë°ì´í„°ë“¤ì€ ë’¤ì— 0(<pad>)ìœ¼ë¡œ ì±„ì›Œì§‘ë‹ˆë‹¤. ì¸ì½”ë”ì˜ ìƒ˜í”Œ í•˜ë‚˜ë§Œ ì¶œë ¥í•´ë³¼ê¹Œìš”?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19  3  8  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n"
     ]
    }
   ],
   "source": [
    "print(encoder_input[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì•ì„œ [19, 3, 8]ì´ë¼ëŠ” 3ê°œì˜ ë‹¨ì–´ë§Œ ìˆë‹¨ ìƒ˜í”Œì´ ë’¤ì— 0ì´ ì±„ì›Œì§€ë©´ì„œ max_eng_seq_lenì˜ ê°’ì¸ 23ì˜ ê¸¸ì´ë¥¼ ê°€ì§€ê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ì œ ê° ì •ìˆ˜ì— ëŒ€í•´ì„œ ë²¡í„°í™” ë°©ë²•ìœ¼ë¡œ ì›-í•« ì¸ì½”ë”©ì„ ì„ íƒí•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì˜ì–´ ë°ì´í„°ì˜ í¬ê¸°(shape) : (50000, 22, 53)\n",
      "í”„ë‘ìŠ¤ì–´ ì…ë ¥ë°ì´í„°ì˜ í¬ê¸°(shape) : (50000, 76, 73)\n",
      "í”„ë‘ìŠ¤ì–´ ì¶œë ¥ë°ì´í„°ì˜ í¬ê¸°(shape) : (50000, 76, 73)\n"
     ]
    }
   ],
   "source": [
    "encoder_input = to_categorical(encoder_input)\n",
    "decoder_input = to_categorical(decoder_input)\n",
    "decoder_target = to_categorical(decoder_target)\n",
    "print('ì˜ì–´ ë°ì´í„°ì˜ í¬ê¸°(shape) :',np.shape(encoder_input))\n",
    "print('í”„ë‘ìŠ¤ì–´ ì…ë ¥ë°ì´í„°ì˜ í¬ê¸°(shape) :',np.shape(decoder_input))\n",
    "print('í”„ë‘ìŠ¤ì–´ ì¶œë ¥ë°ì´í„°ì˜ í¬ê¸°(shape) :',np.shape(decoder_target))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì›-í•« ì¸ì½”ë”©ì„ í•˜ê³ ë‚˜ì„œì˜ ë°ì´í„°ì˜ í¬ê¸°ëŠ” (ìƒ˜í”Œì˜ ìˆ˜ Ã— ìƒ˜í”Œì˜ ê¸¸ì´ Ã— ë‹¨ì–´ì¥ì˜ í¬ê¸°) ê°€ ë©ë‹ˆë‹¤. ì›-í•« ì¸ì½”ë”©ì€ ê° ì •ìˆ˜ë¥¼ ë‹¨ì–´ì¥ì˜ í¬ê¸°ë¥¼ ê°€ì§€ëŠ” ì›-í•« ë²¡í„°ë¡œ ì¸ì½”ë”©í•˜ëŠ” ê³¼ì •ì´ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.\n",
    "\n",
    "ë§ˆì§€ë§‰ìœ¼ë¡œ, í›ˆë ¨ê³¼ì •ì˜ validationì„ ìœ„í•´ ìœ„ì—ì„œ ìƒì„±í•œ ë°ì´í„° 50000ê±´ ì¤‘ 3000ê±´ë§Œ ê²€ì¦ë°ì´í„°ë¡œ ì‚¼ê³ , ë‚˜ë¨¸ì§€ë¥¼ í•™ìŠµë°ì´í„°ë¡œ ì‚¼ê² ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì˜ì–´ í•™ìŠµë°ì´í„°ì˜ í¬ê¸°(shape) : (50000, 22, 53)\n",
      "í”„ë‘ìŠ¤ì–´ í•™ìŠµ ì…ë ¥ë°ì´í„°ì˜ í¬ê¸°(shape) : (50000, 76, 73)\n",
      "í”„ë‘ìŠ¤ì–´ í•™ìŠµ ì¶œë ¥ë°ì´í„°ì˜ í¬ê¸°(shape) : (50000, 76, 73)\n"
     ]
    }
   ],
   "source": [
    "n_of_val = 3000\n",
    "\n",
    "encoder_input_train = encoder_input[:-n_of_val]\n",
    "decoder_input_train = decoder_input[:-n_of_val]\n",
    "decoder_target_train = decoder_target[:-n_of_val]\n",
    "\n",
    "encoder_input_test = encoder_input[-n_of_val:]\n",
    "decoder_input_test = decoder_input[-n_of_val:]\n",
    "decoder_target_test = decoder_target[-n_of_val:]\n",
    "\n",
    "print('ì˜ì–´ í•™ìŠµë°ì´í„°ì˜ í¬ê¸°(shape) :',np.shape(encoder_input))\n",
    "print('í”„ë‘ìŠ¤ì–´ í•™ìŠµ ì…ë ¥ë°ì´í„°ì˜ í¬ê¸°(shape) :',np.shape(decoder_input))\n",
    "print('í”„ë‘ìŠ¤ì–´ í•™ìŠµ ì¶œë ¥ë°ì´í„°ì˜ í¬ê¸°(shape) :',np.shape(decoder_target))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ë²ˆì—­ê¸° ë§Œë“¤ê¸° (2) ëª¨ë¸ í›ˆë ¨í•˜ê¸°\n",
    "ì´ë²ˆ ì‹¤ìŠµì€ ì¼€ë¼ìŠ¤ ì°½ì‹œì í”„ë‘ìˆ˜ì•„ ìˆ„ë ˆì˜ ì¼€ë¼ìŠ¤ seq2seq êµ¬í˜„ ê°€ì´ë“œ A ten-minute introduction to sequence-to-sequence learningì„ ì°¸ê³ ë¡œ í•˜ì˜€ìŠµë‹ˆë‹¤.\n",
    "\n",
    "ìš°ì„  í•„ìš”í•œ ë„êµ¬ë“¤ì„ ì„í¬íŠ¸í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â³\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "print('â³')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ë¨¼ì € ì¸ì½”ë”ë¥¼ ì„¤ê³„í•´ë³¼ê¹Œìš”? ì¸ì½”ë”ëŠ” ë””ì½”ë”ë³´ë‹¤ ìƒëŒ€ì ìœ¼ë¡œ ê°„ë‹¨í•©ë‹ˆë‹¤. ì•ì„œ ì¸ì½”ë”ì˜ ë§ˆì§€ë§‰ hidden stateë¥¼ ë””ì½”ë”ì˜ ì²«ë²ˆì§¸ hidden stateë¡œ ì‚¬ìš©í•œë‹¤ê³  í–ˆì—ˆì§€ìš”? ì¼ë°˜ì ì¸ RNNì˜ ê²½ìš°ì—ëŠ” ê·¸ê²ƒì´ ë§ì§€ë§Œ, ê¸°ë³¸ RNNë³´ë‹¤ ì¢€ ë” ë³µì¡í•œ LSTMì˜ ê²½ìš°ì—ëŠ” hidden stateë¿ë§Œ ì•„ë‹ˆë¼, cell sateë¼ëŠ” ê²ƒì´ ì¡´ì¬í•©ë‹ˆë‹¤.\n",
    "\n",
    "ê·¸ë˜ì„œ ì¸ì½”ë” LSTM ì…€ì˜ ë§ˆì§€ë§‰ time stepì˜ hidden stateì™€ cell stateë¥¼ ë””ì½”ë” LSTMì˜ ì²«ë²ˆì§¸ hidden stateì™€ cell stateë¡œ ì „ë‹¬í•´ì£¼ì–´ì•¼ í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n",
      "\n",
      "systemMemory: 8.00 GB\n",
      "maxCacheSize: 2.67 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-13 14:03:54.558319: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-01-13 14:03:54.558697: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "# ì…ë ¥ í…ì„œ ìƒì„±.\n",
    "encoder_inputs = Input(shape=(None, eng_vocab_size))\n",
    "# hidden sizeê°€ 256ì¸ ì¸ì½”ë”ì˜ LSTM ì…€ ìƒì„±\n",
    "encoder_lstm = LSTM(units = 256, return_state = True)\n",
    "# ë””ì½”ë”ë¡œ ì „ë‹¬í•  hidden state, cell stateë¥¼ ë¦¬í„´. encoder_outputsì€ ì—¬ê¸°ì„œëŠ” ë¶ˆí•„ìš”.\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs)\n",
    "# hidden stateì™€ cell stateë¥¼ ë‹¤ìŒ time stepìœ¼ë¡œ ì „ë‹¬í•˜ê¸° ìœ„í•´ì„œ ë³„ë„ ì €ì¥.\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ìœ„ì˜ ì½”ë“œë¥¼ í•œ ì¤„, í•œ ì¤„ íŒŒì•…í•´ë³¼ê²Œìš”.\n",
    "\n",
    "ì²«ë²ˆì§¸ ì¤„ : ìš°ì„  LSTMì˜ ì…ë ¥ í…ì„œë¥¼ ì •ì˜í•´ì¤ë‹ˆë‹¤. ì…ë ¥ ë¬¸ì¥ì„ ì €ì¥í•˜ê²Œ ë  ë³€ìˆ˜ í…ì„œì…ë‹ˆë‹¤.\n",
    "\n",
    "ë‘ë²ˆì§¸ ì¤„ : 256ì˜ hidden_sizeë¥¼ ê°€ì§€ëŠ” LSTM ì…€ì„ ë§Œë“¤ì–´ì¤ë‹ˆë‹¤. LSTMì˜ ìˆ˜ìš©ë ¥(capacity)ë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤. return_state = Trueë¥¼ í•´ì„œ hidden stateì™€ cell stateë¥¼ ë¦¬í„´ë°›ì„ ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤.\n",
    "\n",
    "ì„¸ë²ˆì§¸ ì¤„ : ì…ë ¥ í…ì„œë¥¼ ì‚¬ìš©í•˜ì—¬ ë§ˆì§€ë§‰ time stepì˜ hidden stateì™€ cell stateë¥¼ ê²°ê³¼ë¡œ ë°›ìŠµë‹ˆë‹¤.\n",
    "\n",
    "ë„¤ë²ˆì§¸ ì¤„ : ë§ˆì§€ë§‰ time stepì˜ hidden stateì™€ cell stateë¥¼ encoder_statesë¼ëŠ” í•˜ë‚˜ì˜ ë³€ìˆ˜ì— ì €ì¥í•´ë’€ìŠµë‹ˆë‹¤. ì´ë¥¼ ë””ì½”ë”ì— ì „ë‹¬í•˜ë©´ ë˜ê² ë„¤ìš”.\n",
    "\n",
    "ì´ì œ ë””ì½”ë”ë¥¼ ì„¤ê³„í•´ë³¼ê¹Œìš”? ë””ì½”ë”ë„ ì¸ì½”ë”ë‘ ëª‡ ê°€ì§€ ì„¸ë¶€ ì‚¬í•­ì„ ì œì™¸í•˜ê³  ê±°ì˜ ë˜‘ê°™ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì…ë ¥ í…ì„œ ìƒì„±.\n",
    "decoder_inputs = Input(shape=(None, fra_vocab_size))\n",
    "# hidden sizeê°€ 256ì¸ ì¸ì½”ë”ì˜ LSTM ì…€ ìƒì„±\n",
    "decoder_lstm = LSTM(units = 256, return_sequences = True, return_state=True)\n",
    "# decoder_outputsëŠ” ëª¨ë“  time stepì˜ hidden state\n",
    "decoder_outputs, _, _= decoder_lstm(decoder_inputs, initial_state = encoder_states)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì„¸ë²ˆì§¸ ì¤„ì„ ë³´ë©´ ë””ì½”ë”ì˜ ì¸ìë¡œ initial_stateê°€ ì¶”ê°€ë˜ì—ˆëŠ”ë°ìš”. LSTM ì…€ì˜ ì´ˆê¸° ìƒíƒœë¥¼ ì •ì˜í•´ì¤„ ìˆ˜ ìˆëŠ” ì¸ìì…ë‹ˆë‹¤. ì—¬ê¸°ì„œëŠ” ì´ì „ì— ì €ì¥í•œ ì¸ì½”ë”ì˜ ë§ˆì§€ë§‰ time stepì˜ hidden stateì™€ cell stateë¥¼ ì‚¬ìš©í•˜ì˜€ìŠµë‹ˆë‹¤. ë””ì½”ë”ì˜ ì¶œë ¥ì¸µì„ ì„¤ê³„í•´ì¤ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_softmax_layer = Dense(fra_vocab_size, activation='softmax')\n",
    "decoder_outputs = decoder_softmax_layer(decoder_outputs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ë§¤ time stepë§ˆë‹¤ì˜ ë‹¤ì¤‘ í´ë˜ìŠ¤ ë¶„ë¥˜ ë¬¸ì œì´ë¯€ë¡œ í”„ë‘ìŠ¤ì–´ ë‹¨ì–´ì¥ìœ¼ë¡œë¶€í„° í•œ ê°€ì§€ ë¬¸ìë§Œ ì„ íƒí•˜ë„ë¡ í•©ë‹ˆë‹¤. Denseì˜ ì¸ìë¡œ í”„ë‘ìŠ¤ì–´ ë‹¨ì–´ì¥ì˜ í¬ê¸°ë¥¼ ê¸°ì¬í•˜ê³ , í™œì„±í™” í•¨ìˆ˜ë¡œ ì†Œí”„íŠ¸ë§¥ìŠ¤ í•¨ìˆ˜ë¥¼ ì‚¬ìš©, ìµœì¢…ì ìœ¼ë¡œ ì¸ì½”ë”ì™€ ë””ì½”ë”ë¥¼ ì—°ê²°í•´ì„œ í•˜ë‚˜ì˜ ëª¨ë¸ë¡œ ë§Œë“¤ì–´ì¤ë‹ˆë‹¤. Modelì˜ Inputê³¼ Outputì˜ ì •ì˜ë¥¼ ìœ ì‹¬íˆ ì‚´í´ ì£¼ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, None, 53)]   0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, None, 73)]   0           []                               \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    [(None, 256),        317440      ['input_1[0][0]']                \n",
      "                                 (None, 256),                                                     \n",
      "                                 (None, 256)]                                                     \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  [(None, None, 256),  337920      ['input_2[0][0]',                \n",
      "                                 (None, 256),                     'lstm[0][1]',                   \n",
      "                                 (None, 256)]                     'lstm[0][2]']                   \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, None, 73)     18761       ['lstm_1[0][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 674,121\n",
      "Trainable params: 674,121\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "opt = tf.keras.optimizers.RMSprop(learning_rate=0.0001)\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer=opt, loss=\"categorical_crossentropy\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-13 14:14:12.328056: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-13 14:14:12.603442: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-13 14:14:12.654268: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-13 14:14:12.773096: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:418 : NOT_FOUND: could not find registered platform with id: 0x15f5f0700\n",
      "2023-01-13 14:14:12.773900: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:418 : NOT_FOUND: could not find registered platform with id: 0x15f5f0700\n",
      "2023-01-13 14:14:12.776710: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "Graph execution error:\n\nDetected at node 'StatefulPartitionedCall_7' defined at (most recent call last):\n    File \"/Users/louan/.pyenv/versions/3.9.13/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/Users/louan/.pyenv/versions/3.9.13/lib/python3.9/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/Users/louan/.pyenv/versions/3.9.13/envs/nlp/lib/python3.9/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/Users/louan/.pyenv/versions/3.9.13/envs/nlp/lib/python3.9/site-packages/traitlets/config/application.py\", line 1041, in launch_instance\n      app.start()\n    File \"/Users/louan/.pyenv/versions/3.9.13/envs/nlp/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 724, in start\n      self.io_loop.start()\n    File \"/Users/louan/.pyenv/versions/3.9.13/envs/nlp/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/Users/louan/.pyenv/versions/3.9.13/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"/Users/louan/.pyenv/versions/3.9.13/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"/Users/louan/.pyenv/versions/3.9.13/lib/python3.9/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/Users/louan/.pyenv/versions/3.9.13/envs/nlp/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 512, in dispatch_queue\n      await self.process_one()\n    File \"/Users/louan/.pyenv/versions/3.9.13/envs/nlp/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 501, in process_one\n      await dispatch(*args)\n    File \"/Users/louan/.pyenv/versions/3.9.13/envs/nlp/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 408, in dispatch_shell\n      await result\n    File \"/Users/louan/.pyenv/versions/3.9.13/envs/nlp/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 731, in execute_request\n      reply_content = await reply_content\n    File \"/Users/louan/.pyenv/versions/3.9.13/envs/nlp/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 417, in do_execute\n      res = shell.run_cell(\n    File \"/Users/louan/.pyenv/versions/3.9.13/envs/nlp/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/Users/louan/.pyenv/versions/3.9.13/envs/nlp/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2945, in run_cell\n      result = self._run_cell(\n    File \"/Users/louan/.pyenv/versions/3.9.13/envs/nlp/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3000, in _run_cell\n      return runner(coro)\n    File \"/Users/louan/.pyenv/versions/3.9.13/envs/nlp/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/Users/louan/.pyenv/versions/3.9.13/envs/nlp/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3203, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/Users/louan/.pyenv/versions/3.9.13/envs/nlp/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3382, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/Users/louan/.pyenv/versions/3.9.13/envs/nlp/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3442, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/var/folders/l5/xccndwgd1qd4v2sfh261kbpm0000gn/T/ipykernel_19037/4209768959.py\", line 1, in <module>\n      model.fit(x=[encoder_input_train, decoder_input_train], y=decoder_target_train, \\\n    File \"/Users/louan/.pyenv/versions/3.9.13/envs/nlp/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/Users/louan/.pyenv/versions/3.9.13/envs/nlp/lib/python3.9/site-packages/keras/engine/training.py\", line 1650, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/Users/louan/.pyenv/versions/3.9.13/envs/nlp/lib/python3.9/site-packages/keras/engine/training.py\", line 1249, in train_function\n      return step_function(self, iterator)\n    File \"/Users/louan/.pyenv/versions/3.9.13/envs/nlp/lib/python3.9/site-packages/keras/engine/training.py\", line 1233, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/louan/.pyenv/versions/3.9.13/envs/nlp/lib/python3.9/site-packages/keras/engine/training.py\", line 1222, in run_step\n      outputs = model.train_step(data)\n    File \"/Users/louan/.pyenv/versions/3.9.13/envs/nlp/lib/python3.9/site-packages/keras/engine/training.py\", line 1027, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"/Users/louan/.pyenv/versions/3.9.13/envs/nlp/lib/python3.9/site-packages/keras/optimizers/optimizer_experimental/optimizer.py\", line 527, in minimize\n      self.apply_gradients(grads_and_vars)\n    File \"/Users/louan/.pyenv/versions/3.9.13/envs/nlp/lib/python3.9/site-packages/keras/optimizers/optimizer_experimental/optimizer.py\", line 1140, in apply_gradients\n      return super().apply_gradients(grads_and_vars, name=name)\n    File \"/Users/louan/.pyenv/versions/3.9.13/envs/nlp/lib/python3.9/site-packages/keras/optimizers/optimizer_experimental/optimizer.py\", line 634, in apply_gradients\n      iteration = self._internal_apply_gradients(grads_and_vars)\n    File \"/Users/louan/.pyenv/versions/3.9.13/envs/nlp/lib/python3.9/site-packages/keras/optimizers/optimizer_experimental/optimizer.py\", line 1166, in _internal_apply_gradients\n      return tf.__internal__.distribute.interim.maybe_merge_call(\n    File \"/Users/louan/.pyenv/versions/3.9.13/envs/nlp/lib/python3.9/site-packages/keras/optimizers/optimizer_experimental/optimizer.py\", line 1216, in _distributed_apply_gradients_fn\n      distribution.extended.update(\n    File \"/Users/louan/.pyenv/versions/3.9.13/envs/nlp/lib/python3.9/site-packages/keras/optimizers/optimizer_experimental/optimizer.py\", line 1211, in apply_grad_to_update_var\n      return self._update_step_xla(grad, var, id(self._var_key(var)))\nNode: 'StatefulPartitionedCall_7'\ncould not find registered platform with id: 0x15f5f0700\n\t [[{{node StatefulPartitionedCall_7}}]] [Op:__inference_train_function_10257]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model\u001b[39m.\u001b[39;49mfit(x\u001b[39m=\u001b[39;49m[encoder_input_train, decoder_input_train], y\u001b[39m=\u001b[39;49mdecoder_target_train, \\\n\u001b[1;32m      2\u001b[0m           validation_data \u001b[39m=\u001b[39;49m ([encoder_input_test, decoder_input_test], decoder_target_test),\n\u001b[1;32m      3\u001b[0m           batch_size\u001b[39m=\u001b[39;49m\u001b[39m128\u001b[39;49m, epochs\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.13/envs/nlp/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.13/envs/nlp/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Graph execution error:\n\nDetected at node 'StatefulPartitionedCall_7' defined at (most recent call last):\n    File \"/Users/louan/.pyenv/versions/3.9.13/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/Users/louan/.pyenv/versions/3.9.13/lib/python3.9/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/Users/louan/.pyenv/versions/3.9.13/envs/nlp/lib/python3.9/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/Users/louan/.pyenv/versions/3.9.13/envs/nlp/lib/python3.9/site-packages/traitlets/config/application.py\", line 1041, in launch_instance\n      app.start()\n    File \"/Users/louan/.pyenv/versions/3.9.13/envs/nlp/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 724, in start\n      self.io_loop.start()\n    File \"/Users/louan/.pyenv/versions/3.9.13/envs/nlp/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/Users/louan/.pyenv/versions/3.9.13/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"/Users/louan/.pyenv/versions/3.9.13/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"/Users/louan/.pyenv/versions/3.9.13/lib/python3.9/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/Users/louan/.pyenv/versions/3.9.13/envs/nlp/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 512, in dispatch_queue\n      await self.process_one()\n    File \"/Users/louan/.pyenv/versions/3.9.13/envs/nlp/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 501, in process_one\n      await dispatch(*args)\n    File \"/Users/louan/.pyenv/versions/3.9.13/envs/nlp/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 408, in dispatch_shell\n      await result\n    File \"/Users/louan/.pyenv/versions/3.9.13/envs/nlp/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 731, in execute_request\n      reply_content = await reply_content\n    File \"/Users/louan/.pyenv/versions/3.9.13/envs/nlp/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 417, in do_execute\n      res = shell.run_cell(\n    File \"/Users/louan/.pyenv/versions/3.9.13/envs/nlp/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/Users/louan/.pyenv/versions/3.9.13/envs/nlp/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2945, in run_cell\n      result = self._run_cell(\n    File \"/Users/louan/.pyenv/versions/3.9.13/envs/nlp/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3000, in _run_cell\n      return runner(coro)\n    File \"/Users/louan/.pyenv/versions/3.9.13/envs/nlp/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/Users/louan/.pyenv/versions/3.9.13/envs/nlp/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3203, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/Users/louan/.pyenv/versions/3.9.13/envs/nlp/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3382, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/Users/louan/.pyenv/versions/3.9.13/envs/nlp/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3442, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/var/folders/l5/xccndwgd1qd4v2sfh261kbpm0000gn/T/ipykernel_19037/4209768959.py\", line 1, in <module>\n      model.fit(x=[encoder_input_train, decoder_input_train], y=decoder_target_train, \\\n    File \"/Users/louan/.pyenv/versions/3.9.13/envs/nlp/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/Users/louan/.pyenv/versions/3.9.13/envs/nlp/lib/python3.9/site-packages/keras/engine/training.py\", line 1650, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/Users/louan/.pyenv/versions/3.9.13/envs/nlp/lib/python3.9/site-packages/keras/engine/training.py\", line 1249, in train_function\n      return step_function(self, iterator)\n    File \"/Users/louan/.pyenv/versions/3.9.13/envs/nlp/lib/python3.9/site-packages/keras/engine/training.py\", line 1233, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/louan/.pyenv/versions/3.9.13/envs/nlp/lib/python3.9/site-packages/keras/engine/training.py\", line 1222, in run_step\n      outputs = model.train_step(data)\n    File \"/Users/louan/.pyenv/versions/3.9.13/envs/nlp/lib/python3.9/site-packages/keras/engine/training.py\", line 1027, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"/Users/louan/.pyenv/versions/3.9.13/envs/nlp/lib/python3.9/site-packages/keras/optimizers/optimizer_experimental/optimizer.py\", line 527, in minimize\n      self.apply_gradients(grads_and_vars)\n    File \"/Users/louan/.pyenv/versions/3.9.13/envs/nlp/lib/python3.9/site-packages/keras/optimizers/optimizer_experimental/optimizer.py\", line 1140, in apply_gradients\n      return super().apply_gradients(grads_and_vars, name=name)\n    File \"/Users/louan/.pyenv/versions/3.9.13/envs/nlp/lib/python3.9/site-packages/keras/optimizers/optimizer_experimental/optimizer.py\", line 634, in apply_gradients\n      iteration = self._internal_apply_gradients(grads_and_vars)\n    File \"/Users/louan/.pyenv/versions/3.9.13/envs/nlp/lib/python3.9/site-packages/keras/optimizers/optimizer_experimental/optimizer.py\", line 1166, in _internal_apply_gradients\n      return tf.__internal__.distribute.interim.maybe_merge_call(\n    File \"/Users/louan/.pyenv/versions/3.9.13/envs/nlp/lib/python3.9/site-packages/keras/optimizers/optimizer_experimental/optimizer.py\", line 1216, in _distributed_apply_gradients_fn\n      distribution.extended.update(\n    File \"/Users/louan/.pyenv/versions/3.9.13/envs/nlp/lib/python3.9/site-packages/keras/optimizers/optimizer_experimental/optimizer.py\", line 1211, in apply_grad_to_update_var\n      return self._update_step_xla(grad, var, id(self._var_key(var)))\nNode: 'StatefulPartitionedCall_7'\ncould not find registered platform with id: 0x15f5f0700\n\t [[{{node StatefulPartitionedCall_7}}]] [Op:__inference_train_function_10257]"
     ]
    }
   ],
   "source": [
    "model.fit(x=[encoder_input_train, decoder_input_train], y=decoder_target_train, \\\n",
    "          validation_data = ([encoder_input_test, decoder_input_test], decoder_target_test),\n",
    "          batch_size=128, epochs=50)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ë²ˆì—­ê¸° ë§Œë“¤ê¸° (3) ëª¨ë¸ í…ŒìŠ¤íŠ¸í•˜ê¸°\n",
    "seq2seqëŠ” í›ˆë ¨í•  ë•Œì™€ í…ŒìŠ¤íŠ¸ ë‹¨ê³„ì˜ ë™ì‘ì´ ë‹¤ë¦…ë‹ˆë‹¤. ì´ë¥¼ ìœ„í•´ì„œ í…ŒìŠ¤íŠ¸ ë‹¨ê³„ì˜ ë””ì½”ë” ëª¨ë¸ì€ ì„¤ê³„ë¥¼ ë‹¤ì‹œ í•´ì¤„ í•„ìš”ê°€ ìˆìŠµë‹ˆë‹¤. ë¬¼ë¡  ì´ì „ì— í•™ìŠµëœ ë””ì½”ë” ëª¨ë¸ì˜ ë ˆì´ì–´ëŠ” ê·¸ëŒ€ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤. ì™œ ì´ë ‡ê²Œ ë²ˆê±°ë¡œìš´ ê³¼ì •ì´ ìƒê¸°ëŠ” ê²ƒì¼ê¹Œìš”? Text Generator ëª¨ë¸ì„ ë§Œë“¤ì–´ ë³´ì‹  ë¶„ì´ë¼ë©´ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤. í›ˆë ¨ì‹œì—ëŠ” í•™ìŠµí•´ì•¼ í•  íƒ€ê²Ÿ ë¬¸ì¥ì„ ë””ì½”ë” ëª¨ë¸ì˜ ì…ë ¥, ì¶œë ¥ ì‹œí€€ìŠ¤ë¡œ ë„£ì–´ ì£¼ê³ , ë””ì½”ë” ëª¨ë¸ì´ íƒ€ê²Ÿ ë¬¸ì¥ì„ í•œêº¼ë²ˆì— ì¶œë ¥í•˜ê²Œ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ í…ŒìŠ¤íŠ¸ ë‹¨ê³„ì—ì„œëŠ” ê·¸ëŸ´ ìˆ˜ê°€ ì—†ìŠµë‹ˆë‹¤. í•˜ë‚˜ì˜ ë¬¸ì¥ì„ ë§Œë“¤ì–´ ë‚´ê¸° ìœ„í•´ ë£¨í”„ë¥¼ ëŒë©° ë‹¨ì–´ë¥¼ í•˜ë‚˜ì”© ì°¨ë¡€ì°¨ë¡€ ì˜ˆì¸¡í•˜ë©´ì„œ, ì˜ˆì¸¡ëœ ë‹¨ì–´ê°€ ë‹¤ìŒ ì…ë ¥ìœ¼ë¡œ ì¬ì‚¬ìš©ë˜ëŠ” ê³¼ì •ì´ ë°˜ë³µë˜ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.\n",
    "\n",
    "ì •ë¦¬í•˜ë©´, í…ŒìŠ¤íŠ¸ ë‹¨ê³„ì—ì„œì˜ ë””ì½”ë”ì˜ ë™ì‘ ìˆœì„œëŠ” ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤.\n",
    "\n",
    "1. ì¸ì½”ë”ì— ì…ë ¥ ë¬¸ì¥ì„ ë„£ì–´ ë§ˆì§€ë§‰ time stepì˜ hidden, cell stateë¥¼ ì–»ëŠ”ë‹¤.\n",
    "2. \\<sos\\> í† í°ì¸ '\\t'ë¥¼ ë””ì½”ë”ì— ì…ë ¥í•œë‹¤.\n",
    "3. ì´ì „ time stepì˜ ì¶œë ¥ì¸µì˜ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ í˜„ì¬ time stepì˜ ì…ë ¥ìœ¼ë¡œ í•œë‹¤.\n",
    "4. 3ì„ ë°˜ë³µí•˜ë‹¤ê°€ \\<eos\\> í† í°ì¸ '\\n'ì´ ì˜ˆì¸¡ë˜ë©´ ì´ë¥¼ ì¤‘ë‹¨í•œë‹¤.\n",
    "\n",
    "í›ˆë ¨ ê³¼ì •ì„ êµ¬í˜„í•˜ëŠ” ê²ƒê³¼ì˜ ì°¨ì´ì ì€, ì´ì „ time stepì˜ ì¶œë ¥ì¸µì˜ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ í˜„ì¬ time stepì˜ ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©í•˜ëŠ” ë‹¨ê³„ë¥¼ ì¶”ê°€í•´ì•¼ í•œë‹¤ëŠ” ê²ƒì…ë‹ˆë‹¤. ê·¸ë ‡ê¸° ë•Œë¬¸ì— ë£¨í”„ë¥¼ ëŒë©° ë””ì½”ë”ì˜ LSTM ì…€ì„ ìˆ˜ë™ ì œì–´í•˜ëŠ” ëŠë‚Œìœ¼ë¡œ ì„¤ê³„í•´ì•¼ í•©ë‹ˆë‹¤. ì½”ë“œê°€ ì¢€ ë” ê¸¸ì–´ì§€ê²Œ ë˜ëŠ”ë°ìš”.\n",
    "\n",
    "ìš°ì„  ì¸ì½”ë”ë¥¼ ì •ì˜í•©ë‹ˆë‹¤. encoder_inputsì™€ encoder_statesëŠ” ì´ë¯¸ ì •ì˜í•œ ê²ƒë“¤ì„ ì¬ì‚¬ìš©í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, None, 53)]        0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 [(None, 256),             317440    \n",
      "                              (None, 256),                       \n",
      "                              (None, 256)]                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 317,440\n",
      "Trainable params: 317,440\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_model = Model(inputs = encoder_inputs, outputs = encoder_states)\n",
    "encoder_model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì´ì œ ë””ì½”ë”ë¥¼ ì„¤ê³„í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì´ì „ time stepì˜ hidden stateë¥¼ ì €ì¥í•˜ëŠ” í…ì„œ\n",
    "decoder_state_input_h = Input(shape=(256,))\n",
    "# ì´ì „ time stepì˜ cell stateë¥¼ ì €ì¥í•˜ëŠ” í…ì„œ\n",
    "decoder_state_input_c = Input(shape=(256,))\n",
    "# ì´ì „ time stepì˜ hidden stateì™€ cell stateë¥¼ í•˜ë‚˜ì˜ ë³€ìˆ˜ì— ì €ì¥\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "# decoder_states_inputsë¥¼ í˜„ì¬ time stepì˜ ì´ˆê¸° ìƒíƒœë¡œ ì‚¬ìš©.\n",
    "# êµ¬ì²´ì ì¸ ë™ì‘ ìì²´ëŠ” def decode_sequence()ì— êµ¬í˜„.\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state = decoder_states_inputs)\n",
    "# í˜„ì¬ time stepì˜ hidden stateì™€ cell stateë¥¼ í•˜ë‚˜ì˜ ë³€ìˆ˜ì— ì €ì¥.\n",
    "decoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "í›ˆë ¨ ê³¼ì •ì—ì„œì˜ ë””ì½”ë”ë³´ë‹¤ ì½”ë“œê°€ ì¢€ ë” ê¸¸ì–´ì¡Œì£ ? ì´ì „ time stepì˜ ì¶œë ¥ ê²°ê³¼ë¥¼ í˜„ì¬ time stepì˜ ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©í•˜ê¸° ìœ„í•´ì„œ ë””ì½”ë” LSTM ì…€ì˜ ë™ì‘ì„ ì¢€ ë” ì„¸ë¶„í™”í•´ì„œ êµ¬í˜„í–ˆìŠµë‹ˆë‹¤. ë™ì‘ ìì²´ëŠ” ì´í›„ì— êµ¬í˜„í•  í•¨ìˆ˜ decode_sequence()ì—ì„œ ì¢€ ë” ìì„¸íˆ ë‹¤ë£¨ê² ìŠµë‹ˆë‹¤.\n",
    "\n",
    "ë””ì½”ë”ì˜ ì¶œë ¥ì¸µì„ ì¬ì„¤ê³„í•´ì¤ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, None, 73)]   0           []                               \n",
      "                                                                                                  \n",
      " input_3 (InputLayer)           [(None, 256)]        0           []                               \n",
      "                                                                                                  \n",
      " input_4 (InputLayer)           [(None, 256)]        0           []                               \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  [(None, None, 256),  337920      ['input_2[0][0]',                \n",
      "                                 (None, 256),                     'input_3[0][0]',                \n",
      "                                 (None, 256)]                     'input_4[0][0]']                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, None, 73)     18761       ['lstm_1[1][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 356,681\n",
      "Trainable params: 356,681\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder_outputs = decoder_softmax_layer(decoder_outputs)\n",
    "decoder_model = Model(inputs=[decoder_inputs] + decoder_states_inputs, outputs=[decoder_outputs] + decoder_states)\n",
    "decoder_model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ë‹¨ì–´ì—ì„œ ì •ìˆ˜ë¡œ, ì •ìˆ˜ì—ì„œ ë‹¨ì–´ë¡œ ë°”ê¾¸ëŠ” ì‚¬ì „(dictionary)ì„ ì¤€ë¹„í•´ ë‘¡ë‹ˆë‹¤. í…ŒìŠ¤íŠ¸ ê²°ê³¼ë¥¼ í•´ì„í•˜ê¸° ìœ„í•´ì„  ë‹¤ì‹œ ì‚¬ì „ì´ í•„ìš”í•˜ê² ì£ ? ìš°ë¦¬ëŠ” ì´ì „ ìŠ¤í…ì—ì„œ ë¬¸ì¥ì„ ìˆ«ì ì¸ë±ìŠ¤ë¡œ ë°”ê¾¸ëŠ” Tokenizerë¥¼ ë§Œë“¤ë©´ì„œ ìë™ìœ¼ë¡œ ë§Œë“¤ì–´ì§„ ì‚¬ì „ì„ ì´ë¯¸ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng2idx = eng_tokenizer.word_index\n",
    "fra2idx = fra_tokenizer.word_index\n",
    "idx2eng = eng_tokenizer.index_word\n",
    "idx2fra = fra_tokenizer.index_word"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì´ì œ ì˜ˆì¸¡ ê³¼ì •ì„ ìœ„í•œ í•¨ìˆ˜ decode_sequence()ë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤. decode_sequence()ì˜ ì…ë ¥ìœ¼ë¡œ ë“¤ì–´ê°€ëŠ” ê²ƒì€ ë²ˆì—­í•˜ê³ ì í•˜ëŠ” ë¬¸ì¥ì˜ ì •ìˆ˜ ì‹œí€€ìŠ¤ì…ë‹ˆë‹¤. decode_sequence() ë‚´ë¶€ì—ëŠ” ì¸ì½”ë”ë¥¼ êµ¬í˜„í•œ encoder_modelì´ ìˆì–´ì„œ ì´ ëª¨ë¸ì— ë²ˆì—­í•˜ê³ ì í•˜ëŠ” ë¬¸ì¥ì˜ ì •ìˆ˜ ì‹œí€€ìŠ¤ì¸ 'input_seq'ë¥¼ ì…ë ¥í•˜ë©´, encoder_modelì€ ë§ˆì§€ë§‰ ì‹œì ì˜ hidden stateë¥¼ ë¦¬í„´í•©ë‹ˆë‹¤.\n",
    "\n",
    "```\n",
    "# decode_sequence() í•¨ìˆ˜ ë‚´ì— ìˆëŠ” ì½”ë“œ\n",
    "states_value = encoder_model.predict(input_seq)\n",
    "```\n",
    "\n",
    "ì´ hidden stateëŠ” ë””ì½”ë”ì˜ ì²«ë²ˆì§¸ ì‹œì ì˜ hidden stateê°€ ë˜ê³ , ë””ì½”ë”ëŠ” ì´ì œ ë²ˆì—­ ë¬¸ì¥ì„ ì™„ì„±í•˜ê¸° ìœ„í•œ ì˜ˆì¸¡ ê³¼ì •ì„ ì§„í–‰í•©ë‹ˆë‹¤. ë””ì½”ë”ì˜ ì˜ˆì¸¡ ê³¼ì •ì—ì„œëŠ” ì´ì „ ì‹œì ì—ì„œ ì˜ˆì¸¡í•œ ë‹¨ì–´ë¥¼ ë””ì½”ë”ì˜ í˜„ì¬ ì‹œì ì˜ ì…ë ¥ìœ¼ë¡œ ë„£ì–´ì£¼ëŠ” ì‘ì—…ì„ ì§„í–‰í•©ë‹ˆë‹¤. ê·¸ë¦¬ê³  ì´ ì‘ì—…ì€ ì¢…ë£Œë¥¼ ì˜ë¯¸í•˜ëŠ” ì¢…ë£Œ í† í°ì„ ë§Œë‚˜ê±°ë‚˜, ì£¼ì–´ì§„ ìµœëŒ€ ê¸¸ì´ë¥¼ ë„˜ì„ ë•Œê¹Œì§€ ë°˜ë³µí•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # ì…ë ¥ìœ¼ë¡œë¶€í„° ì¸ì½”ë”ì˜ ìƒíƒœë¥¼ ì–»ìŒ\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # <SOS>ì— í•´ë‹¹í•˜ëŠ” ì›-í•« ë²¡í„° ìƒì„±\n",
    "    target_seq = np.zeros((1, 1, fra_vocab_size))\n",
    "    target_seq[0, 0, fra2idx['\\t']] = 1.\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = \"\"\n",
    "\n",
    "    # stop_conditionì´ Trueê°€ ë  ë•Œê¹Œì§€ ë£¨í”„ ë°˜ë³µ\n",
    "    while not stop_condition:\n",
    "        # ì´ì  ì‹œì ì˜ ìƒíƒœ states_valueë¥¼ í˜„ ì‹œì ì˜ ì´ˆê¸° ìƒíƒœë¡œ ì‚¬ìš©\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        # ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ë¬¸ìë¡œ ë³€í™˜\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = idx2fra[sampled_token_index]\n",
    "\n",
    "        # í˜„ì¬ ì‹œì ì˜ ì˜ˆì¸¡ ë¬¸ìë¥¼ ì˜ˆì¸¡ ë¬¸ì¥ì— ì¶”ê°€\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        # <eos>ì— ë„ë‹¬í•˜ê±°ë‚˜ ìµœëŒ€ ê¸¸ì´ë¥¼ ë„˜ìœ¼ë©´ ì¤‘ë‹¨.\n",
    "        if (sampled_char == '\\n' or\n",
    "           len(decoded_sentence) > max_fra_seq_len):\n",
    "            stop_condition = True\n",
    "\n",
    "        # í˜„ì¬ ì‹œì ì˜ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ë‹¤ìŒ ì‹œì ì˜ ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©í•˜ê¸° ìœ„í•´ ì €ì¥\n",
    "        target_seq = np.zeros((1, 1, fra_vocab_size))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "        # í˜„ì¬ ì‹œì ì˜ ìƒíƒœë¥¼ ë‹¤ìŒ ì‹œì ì˜ ìƒíƒœë¡œ ì‚¬ìš©í•˜ê¸° ìœ„í•´ ì €ì¥\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì´ë ‡ê²Œ êµ¬í˜„í•œ í•¨ìˆ˜ì— ë²ˆì—­í•˜ê³ ì í•˜ëŠ” ë¬¸ì¥ì˜ ì¸ë±ìŠ¤ë¥¼ ì„ì˜ë¡œ ì…ë ¥í•˜ì—¬ ì¶œë ¥ ê²°ê³¼ë¥¼ í…ŒìŠ¤íŠ¸í•´ë³´ê² ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-13 14:19:26.473685: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-13 14:19:26.519721: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 553ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-13 14:19:27.057625: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-13 14:19:27.108544: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 564ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "-----------------------------------\n",
      "ì…ë ¥ ë¬¸ì¥: Go.\n",
      "ì •ë‹µ ë¬¸ì¥:  Bouge ! \n",
      "ë²ˆì—­ê¸°ê°€ ë²ˆì—­í•œ ë¬¸ì¥: 333eee3eeeâ€˜!!(((Â«\"k4444444  :::::Ã ::Ã yyoooÃ©Ã©fÃ©444444  :::::Ã ::Ã yyoooÃ©Ã©fÃ©4444\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "-----------------------------------\n",
      "ì…ë ¥ ë¬¸ì¥: Hello!\n",
      "ì •ë‹µ ë¬¸ì¥:  Bonjour ! \n",
      "ë²ˆì—­ê¸°ê°€ ë²ˆì—­í•œ ë¬¸ì¥: 333eee3eeÃ´!â€˜!(((Â«\"k4444444  :::::Ã ::Ã yyoooÃ©Ã©fÃ©444444  :::::Ã ::Ã yyoooÃ©Ã©fÃ©4444\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "-----------------------------------\n",
      "ì…ë ¥ ë¬¸ì¥: Got it?\n",
      "ì •ë‹µ ë¬¸ì¥:  T'as captÃ©â€¯? \n",
      "ë²ˆì—­ê¸°ê°€ ë²ˆì—­í•œ ë¬¸ì¥: 333eee3eeÃ´!â€˜!(((Â«\"k4444444  :::::Ã ::Ã yyoooÃ©Ã©fÃ©444444  :::::Ã ::Ã yyoooÃ©Ã©fÃ©4444\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mfor\u001b[39;00m seq_index \u001b[39min\u001b[39;00m [\u001b[39m3\u001b[39m,\u001b[39m50\u001b[39m,\u001b[39m100\u001b[39m,\u001b[39m300\u001b[39m,\u001b[39m1001\u001b[39m]: \u001b[39m# ì…ë ¥ ë¬¸ì¥ì˜ ì¸ë±ìŠ¤ (ììœ ë¡­ê²Œ ì„ íƒí•´ ë³´ì„¸ìš”)\u001b[39;00m\n\u001b[1;32m      3\u001b[0m     input_seq \u001b[39m=\u001b[39m encoder_input[seq_index: seq_index \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m]\n\u001b[0;32m----> 4\u001b[0m     decoded_sentence \u001b[39m=\u001b[39m decode_sequence(input_seq)\n\u001b[1;32m      5\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m35\u001b[39m \u001b[39m*\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m-\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mì…ë ¥ ë¬¸ì¥:\u001b[39m\u001b[39m'\u001b[39m, lines\u001b[39m.\u001b[39meng[seq_index])\n",
      "Cell \u001b[0;32mIn[39], line 19\u001b[0m, in \u001b[0;36mdecode_sequence\u001b[0;34m(input_seq)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[39m# ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ë¬¸ìë¡œ ë³€í™˜\u001b[39;00m\n\u001b[1;32m     18\u001b[0m sampled_token_index \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margmax(output_tokens[\u001b[39m0\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, :])\n\u001b[0;32m---> 19\u001b[0m sampled_char \u001b[39m=\u001b[39m idx2fra[sampled_token_index]\n\u001b[1;32m     21\u001b[0m \u001b[39m# í˜„ì¬ ì‹œì ì˜ ì˜ˆì¸¡ ë¬¸ìë¥¼ ì˜ˆì¸¡ ë¬¸ì¥ì— ì¶”ê°€\u001b[39;00m\n\u001b[1;32m     22\u001b[0m decoded_sentence \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m sampled_char\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "for seq_index in [3,50,100,300,1001]: # ì…ë ¥ ë¬¸ì¥ì˜ ì¸ë±ìŠ¤ (ììœ ë¡­ê²Œ ì„ íƒí•´ ë³´ì„¸ìš”)\n",
    "    input_seq = encoder_input[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print(35 * \"-\")\n",
    "    print('ì…ë ¥ ë¬¸ì¥:', lines.eng[seq_index])\n",
    "    print('ì •ë‹µ ë¬¸ì¥:', lines.fra[seq_index][1:len(lines.fra[seq_index])-1]) # '\\t'ì™€ '\\n'ì„ ë¹¼ê³  ì¶œë ¥\n",
    "    print('ë²ˆì—­ê¸°ê°€ ë²ˆì—­í•œ ë¬¸ì¥:', decoded_sentence[:len(decoded_sentence)-1]) # '\\n'ì„ ë¹¼ê³  ì¶œë ¥"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì¼ë¶€ ì •ë‹µ ë¬¸ì¥ê³¼ ë‹¤ë¥¸ ë²ˆì—­ì„ í•˜ëŠ” ê²½ìš°ë„ ìˆì§€ë§Œ, ëŒ€ì²´ì ìœ¼ë¡œ ì •ë‹µ ë¬¸ì¥ê³¼ ê±°ì˜ ë¹„ìŠ·í•œ ë²ˆì—­ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Dec 30 2022, 12:26:09) \n[Clang 14.0.0 (clang-1400.0.29.202)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "82539e9657ddf6135d2a67b698e4c6b6f8ca39faefdcea3cd628041ec1676e2f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
