{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 프로젝트 : 단어 Level로 번역기 업그레이드하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.11.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import string\n",
    "import re\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "실습에서 구현한 번역기는 글자 단위(Character-level)에서 구현된 번역기였습니다. 하지만 실제 번역기의 경우에는 글자 단위가 아니라 단어 단위(Word-level)에서 구현되는 것이 좀 더 보편적입니다.\n",
    "\n",
    "동일한 데이터셋을 사용하면서 글자 단위와는 다른 전처리와 to_categorical() 함수가 아닌 임베딩 층(Embedding layer)를 추가하여 단어 단위의 번역기를 완성시켜보겠습니다. 하지만, 단어 단위로 할 경우에는 단어의 개수가 글자 단위로 했을 경우와 비교하여 단어장의 크기(Vocabulary) 크기도 커지고, 학습 속도도 좀 더 느려집니다. 학습과 테스트 시의 원활한 진행을 위해서 데이터에서 상위 33,000개의 샘플만 사용해주세요.\n",
    "\n",
    "33000개 중 3000개는 테스트 데이터로 분리하여 모델을 학습한 후에 번역을 테스트 하는 용도로 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플의 수 : 33000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>fra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Buy it.</td>\n",
       "      <td>Achetez-le !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24301</th>\n",
       "      <td>I owe you nothing.</td>\n",
       "      <td>Je ne vous dois rien.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30878</th>\n",
       "      <td>Is this your house?</td>\n",
       "      <td>Est-ce que cette maison t'appartient ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32292</th>\n",
       "      <td>They're mad at you.</td>\n",
       "      <td>Ils sont furieux après vous.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15974</th>\n",
       "      <td>They're leaving.</td>\n",
       "      <td>Ils s'en vont.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       eng                                     fra\n",
       "81                 Buy it.                            Achetez-le !\n",
       "24301   I owe you nothing.                   Je ne vous dois rien.\n",
       "30878  Is this your house?  Est-ce que cette maison t'appartient ?\n",
       "32292  They're mad at you.            Ils sont furieux après vous.\n",
       "15974     They're leaving.                          Ils s'en vont."
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data 불러오기\n",
    "file_path = '../data/230113/fra.txt'\n",
    "lines = pd.read_csv(file_path, names=['eng', 'fra', 'cc'], sep='\\t')\n",
    "lines = lines[['eng', 'fra']][:33000] # 3.3만개 샘플 사용\n",
    "print('전체 샘플의 수 :',len(lines))\n",
    "lines.sample(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. 정제, 정규화, 전처리 (영어, 프랑스어 모두!)\n",
    "---\n",
    "\n",
    "글자 단위가 아닌 단어 단위의 번역기를 하기 위해서는 글자 단위에서는 신경쓰지 않았던 몇 가지 추가적인 전처리가 필요합니다.\n",
    "\n",
    "### 1. 구두점(Punctuation)을 단어와 분리해주세요.\n",
    "일반적으로 영어권 언어의 경우에는 띄어쓰기 단위로 단어를 분리합니다. 토큰화(Tokenization) 라고도 불리는 이 작업은 어디서부터 어디까지가 하나의 단어인지를 구분하는 작업인데요, 그런데 띄어쓰기를 해주기 전에 구두점을 분리하는 작업이 필요할 때가 있습니다.\n",
    "예를 들어서 'he is a good boy!'라는 문장이 있을 때, 이를 띄어쓰기 단위로 토큰화한다면 ['he', 'is', 'a', 'good', 'boy!']가 됩니다. 그런데 실제로 !는 boy와 붙어있는 한 단어가 아니므로 좀 더 올바른 전처리는 ['he', 'is', 'a', 'good', 'boy', '!']가 맞습니다.\n",
    "!나 ? 또는 온점과 같은 특수문자들을 구두점(punctuation)이라고 부릅니다. 이들을 토큰화하기 전에 단어와 미리 분리시켜주세요!\n",
    "\n",
    "- 분리 전 : he is a Good boy!\n",
    "- 분리 후 : he is a Good boy !\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 소문자로 바꿔주세요.\n",
    "\n",
    "기계가 보기에는 스펠링이 같더라도 대문자로 된 단어와 소문자로 된 단어는 서로 다른 단어입니다. 예를 들어 'Good'과 'good'은 기계가 보기에는 다른 단어입니다. 그래서 모든 문장에 대해서 전부 영어로 바꿔주는 작업을 하겠습니다.\n",
    "\n",
    "변환 전 : he is a Good boy !\n",
    "변환 후 : he is a good boy !\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'he is a good boy !'"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 참고: https://stackoverflow.com/questions/20705832/python-regex-inserting-a-space-between-punctuation-and-letters\n",
    "def apply_regex(string_var):\n",
    "    temp = re.sub(r'([a-zA-Z]+)([!\\\"#$%&\\'()*+,-./:;<=>?@[\\]^_`{|}~])', r'\\1 \\2', string_var) \n",
    "    temp = re.sub(r'([!\\\"#$%&\\'()*+,-./:;<=>?@[\\]^_`{|}~])([a-zA-Z])', r'\\1 \\2', temp) \n",
    "    temp = re.sub(r'([!\\\"#$%&\\'()*+,-./:;<=>?@[\\]^_`{|}~]?)([!\\\"#$%&\\'()*+,-./:;<=>?@[\\]^_`{|}~])', r'\\1 \\2', temp) \n",
    "    temp = re.sub(r'\\s+', r' ', temp) \n",
    "    return temp\n",
    "sentence = apply_regex(\"He is a Good boy!\").lower()\n",
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 띄어쓰기 단위로 토큰화를 수행하세요.\n",
    "#### Step 1.띄어쓰기 단위로 토큰화를 수행해서 단어를 분리하는 작업을 해주세요. 기계는 이렇게 분리된 토큰들을 각각 하나의 단어로 인식할 수 있게 됩니다.\n",
    "---\n",
    "\n",
    "토큰화 전 : 'he is a good boy !'\n",
    "토큰화 후 : ['he', 'is', 'a', 'good', 'boy', '!']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['he', 'is', 'a', 'good', 'boy', '!']"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token = sentence.split(' ')\n",
    "token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>fra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[go, .]</td>\n",
       "      <td>[va, !]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[go, .]</td>\n",
       "      <td>[marche, .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[go, .]</td>\n",
       "      <td>[en, route, !]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[go, .]</td>\n",
       "      <td>[bouge, !]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[hi, .]</td>\n",
       "      <td>[salut, !]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[hi, .]</td>\n",
       "      <td>[salut, .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[run, !]</td>\n",
       "      <td>[cours, !]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[run, !]</td>\n",
       "      <td>[courez, !]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[run, !]</td>\n",
       "      <td>[prenez, vos, jambes, à, vos, cous, !]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[run, !]</td>\n",
       "      <td>[file, !]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        eng                                     fra\n",
       "0   [go, .]                                 [va, !]\n",
       "1   [go, .]                             [marche, .]\n",
       "2   [go, .]                          [en, route, !]\n",
       "3   [go, .]                              [bouge, !]\n",
       "4   [hi, .]                              [salut, !]\n",
       "5   [hi, .]                              [salut, .]\n",
       "6  [run, !]                              [cours, !]\n",
       "7  [run, !]                             [courez, !]\n",
       "8  [run, !]  [prenez, vos, jambes, à, vos, cous, !]\n",
       "9  [run, !]                               [file, !]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 단어 정제 및 띄어쓰기 적용하기 \n",
    "train_lines_new = train_data.copy()\n",
    "train_lines_new.eng = train_lines_new.eng.apply(lambda x : apply_regex(x).lower().split())\n",
    "train_lines_new.fra = train_lines_new.fra.apply(lambda x : apply_regex(x).lower().split())\n",
    "train_lines_new.head(10)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2. 디코더의 문장에 시작 토큰과 종료 토큰을 넣어주세요.\n",
    "---\n",
    "\n",
    "글자 단위 번역기를 구현할 때와 마찬가지로 디코더의 입력 시퀀스 맨 앞에는 시작을 의미하는 토큰인 \\<sos\\>가 필요합니다. 그리고 교사 강요를 수행할 때, 디코더의 실제값이 되는 디코더의 레이블 시퀀스에는 종료를 의미하는 종료 토큰 \\<eos\\>가 필요합니다.\n",
    "예를 들어 번역 문장이 \"Courez!\" 였다고 한다면, Step 1을 거친 후에는 다음과 같은 결과를 얻습니다.\n",
    "\n",
    "Step 1을 수행한 후 : ['courez', '!']\n",
    "이 문장에 대해서 각각 디코더의 입력 시퀀스와 레이블 시퀀스를 만들면 다음과 같습니다.\n",
    "\n",
    "입력 시퀀스 : ['\\<sos\\>', 'courez', '!']\n",
    "레이블 시퀀스 : ['courez', '!', '\\<eos\\>']\n",
    "참고로 Step 2가 반드시 Step 1이 끝난 후에 이루어질 필요는 없습니다!\n",
    "Step 1을 수행하는 중간에 수행해도 상관없습니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lines_new.fra = train_lines_new.fra.apply(lambda x : ['<sos>'] + x+ ['<eos>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           [<sos>, va, !, <eos>]\n",
       "1       [<sos>, marche, ., <eos>]\n",
       "2    [<sos>, en, route, !, <eos>]\n",
       "3        [<sos>, bouge, !, <eos>]\n",
       "4        [<sos>, salut, !, <eos>]\n",
       "Name: fra, dtype: object"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_lines_new.fra.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3. 케라스의 토크나이저로 텍스트를 숫자로 바꿔보세요.\n",
    "---\n",
    "\n",
    "딥러닝 모델은 텍스트가 아닌 숫자를 처리합니다. 케라스 토크나이저를 사용해서 각 단어를 고유한 정수로 바꿔보세요.\n",
    "케라스 토크나이저의 사용법은 아래의 링크에서 2. 케라스(Keras)의 텍스트 전처리에 설명되어 있습니다.\n",
    "\n",
    "위키독스\n",
    "위 링크의 가이드를 통해서 영어와 프랑스어에 대한 토크나이저를 각각 생성하고, tokenizer.texts_to_sequences()를 사용하여 모든 샘플에 대해서 정수 시퀀스로 변환해보세요.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[28, 1], [28, 1], [28, 1]]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_tokenizer = Tokenizer(char_level=False)\n",
    "eng_tokenizer.fit_on_texts(train_lines_new.eng)\n",
    "input_text = eng_tokenizer.texts_to_sequences(train_lines_new.eng)\n",
    "encoder_input = input_text\n",
    "input_text[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 70, 10, 2], [1, 311, 3, 2], [1, 27, 491, 10, 2]]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fra_tokenizer = Tokenizer(char_level=False)\n",
    "fra_tokenizer.fit_on_texts(train_lines_new.fra)\n",
    "target_text = fra_tokenizer.texts_to_sequences(train_lines_new.fra)\n",
    "target_text[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[1, 70, 10], [1, 311, 3], [1, 27, 491, 10]],\n",
       " [[70, 10, 2], [311, 3, 2], [27, 491, 10, 2]])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_input = [[ char for char in line if char != fra_tokenizer.word_index['<eos>'] ] for line in target_text] \n",
    "decoder_target = [[ char for char in line if char != fra_tokenizer.word_index['<sos>'] ] for line in target_text] \n",
    "decoder_input[:3], decoder_target[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
    "fra_vocab_size = len(fra_tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_eng_seq_len = max([len(line) for line in input_text])\n",
    "max_fra_seq_len = max([len(line) for line in target_text])\n",
    "encoder_input = pad_sequences(encoder_input, maxlen = max_eng_seq_len, padding='post')\n",
    "decoder_input = pad_sequences(decoder_input, maxlen = max_fra_seq_len, padding='post')\n",
    "decoder_target = pad_sequences(decoder_target, maxlen = max_fra_seq_len, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 28   1   0   0   0   0   0   0   0]\n",
      " [ 28   1   0   0   0   0   0   0   0]\n",
      " [ 28   1   0   0   0   0   0   0   0]\n",
      " [ 28   1   0   0   0   0   0   0   0]\n",
      " [747   1   0   0   0   0   0   0   0]\n",
      " [747   1   0   0   0   0   0   0   0]\n",
      " [177  22   0   0   0   0   0   0   0]\n",
      " [177  22   0   0   0   0   0   0   0]\n",
      " [177  22   0   0   0   0   0   0   0]\n",
      " [177  22   0   0   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "# padding 결과\n",
    "print(encoder_input[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_of_val = 3000\n",
    "\n",
    "encoder_input_train = encoder_input[:-n_of_val]\n",
    "decoder_input_train = decoder_input[:-n_of_val]\n",
    "decoder_target_train = decoder_target[:-n_of_val]\n",
    "\n",
    "encoder_input_test = encoder_input[-n_of_val:]\n",
    "decoder_input_test = decoder_input[-n_of_val:]\n",
    "decoder_target_test = decoder_target[-n_of_val:]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4. 임베딩 층(Embedding layer) 사용하기\n",
    "---\n",
    "\n",
    "이번에는 입력이 되는 각 단어를 임베딩 층을 사용하여 벡터화하겠습니다.\n",
    "임베딩 층을 사용하는 방법과 그 설명에 대해서는 아래의 링크의 1. 케라스 임베딩 층(Keras Embedding layer) 을 참고하세요.\n",
    "\n",
    "- [위키독스](https://wikidocs.net/33793)\n",
    "실제 번역기 구현을 위해서 사용할 수 있는 인코더 코드의 예시는 다음과 같습니다. 이를 통해서 인코더와 디코더의 임베딩 층을 각각 구현해보세요.\n",
    "```\n",
    "from tensorflow.keras.layers import Input, Embedding, Masking\n",
    "\n",
    "# 인코더에서 사용할 임베딩 층 사용 예시\n",
    "encoder_inputs = Input(shape=(None,))\n",
    "enc_emb =  Embedding(단어장의 크기, 임베딩 벡터의 차원)(encoder_inputs)\n",
    "encoder_lstm = LSTM(hidden state의 크기, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(enc_emb)\n",
    "```\n",
    "주의할 점은 인코더와 디코더의 임베딩 층은 서로 다른 임베딩 층을 사용해야 하지만, 디코더의 훈련 과정과 테스트 과정(예측 과정)에서의 임베딩 층은 동일해야 한다는 것입니다!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5. 모델 구현하기\n",
    "--- \n",
    "\n",
    "글자 단위 번역기에서 구현한 모델을 참고로 단어 단위 번역기의 모델을 완성시켜보세요! 이때는 label이 integer 값이므로 categorical entropy loss가 아닌 sparse categorical entropy loss를 사용합니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Embedding, Masking, LSTM, Dense\n",
    "\n",
    "encoder_inputs = Input(shape=(None,))\n",
    "enc_emb =  Embedding(eng_vocab_size, 256, input_length = max_eng_seq_len)(encoder_inputs)\n",
    "encoder_lstm = LSTM(units = 128, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(enc_emb)\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_inputs = Input(shape=(None,))\n",
    "fra_emb =  Embedding(fra_vocab_size, 256, input_length = max_fra_seq_len)(decoder_inputs)\n",
    "decoder_lstm = LSTM(units = 128, return_sequences = True, return_state=True)\n",
    "decoder_outputs, _, _= decoder_lstm(fra_emb, initial_state = encoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_softmax_layer = Dense(fra_vocab_size, activation='softmax')\n",
    "decoder_outputs = decoder_softmax_layer(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_32 (InputLayer)          [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " input_33 (InputLayer)          [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " embedding_23 (Embedding)       (None, None, 256)    1127936     ['input_32[0][0]']               \n",
      "                                                                                                  \n",
      " embedding_24 (Embedding)       (None, None, 256)    2086144     ['input_33[0][0]']               \n",
      "                                                                                                  \n",
      " lstm_30 (LSTM)                 [(None, 128),        197120      ['embedding_23[0][0]']           \n",
      "                                 (None, 128),                                                     \n",
      "                                 (None, 128)]                                                     \n",
      "                                                                                                  \n",
      " lstm_31 (LSTM)                 [(None, None, 128),  197120      ['embedding_24[0][0]',           \n",
      "                                 (None, 128),                     'lstm_30[0][1]',                \n",
      "                                 (None, 128)]                     'lstm_30[0][2]']                \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, None, 8149)   1051221     ['lstm_31[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,659,541\n",
      "Trainable params: 4,659,541\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "\n",
    "opt = tf.keras.optimizers.legacy.RMSprop(learning_rate=0.0001)\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer=opt, loss=\"sparse_categorical_crossentropy\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-20 09:57:22.484501: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-20 09:57:22.839816: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-20 09:57:22.931115: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-20 09:57:23.224319: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-20 09:57:23.363353: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "211/211 [==============================] - ETA: 0s - loss: 6.1759"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-20 09:57:39.964349: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-20 09:57:40.093952: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-20 09:57:40.144134: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "211/211 [==============================] - 20s 84ms/step - loss: 6.1759 - val_loss: 3.7672\n",
      "Epoch 2/50\n",
      "211/211 [==============================] - 14s 67ms/step - loss: 2.5053 - val_loss: 2.2868\n",
      "Epoch 3/50\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 1.8251 - val_loss: 1.9917\n",
      "Epoch 4/50\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 1.6037 - val_loss: 1.8289\n",
      "Epoch 5/50\n",
      "211/211 [==============================] - 14s 66ms/step - loss: 1.4672 - val_loss: 1.7244\n",
      "Epoch 6/50\n",
      "211/211 [==============================] - 15s 71ms/step - loss: 1.3762 - val_loss: 1.6510\n",
      "Epoch 7/50\n",
      "211/211 [==============================] - 20s 93ms/step - loss: 1.3079 - val_loss: 1.5918\n",
      "Epoch 8/50\n",
      "211/211 [==============================] - 17s 83ms/step - loss: 1.2538 - val_loss: 1.5406\n",
      "Epoch 9/50\n",
      "211/211 [==============================] - 17s 82ms/step - loss: 1.2131 - val_loss: 1.5027\n",
      "Epoch 10/50\n",
      "211/211 [==============================] - 17s 79ms/step - loss: 1.1811 - val_loss: 1.4741\n",
      "Epoch 11/50\n",
      "211/211 [==============================] - 14s 66ms/step - loss: 1.1542 - val_loss: 1.4457\n",
      "Epoch 12/50\n",
      "211/211 [==============================] - 14s 66ms/step - loss: 1.1286 - val_loss: 1.4187\n",
      "Epoch 13/50\n",
      "211/211 [==============================] - 14s 66ms/step - loss: 1.1050 - val_loss: 1.3938\n",
      "Epoch 14/50\n",
      "211/211 [==============================] - 14s 66ms/step - loss: 1.0832 - val_loss: 1.3720\n",
      "Epoch 15/50\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 1.0641 - val_loss: 1.3526\n",
      "Epoch 16/50\n",
      "211/211 [==============================] - 14s 68ms/step - loss: 1.0469 - val_loss: 1.3354\n",
      "Epoch 17/50\n",
      "211/211 [==============================] - 18s 86ms/step - loss: 1.0305 - val_loss: 1.3158\n",
      "Epoch 18/50\n",
      "211/211 [==============================] - 19s 89ms/step - loss: 1.0152 - val_loss: 1.2990\n",
      "Epoch 19/50\n",
      "211/211 [==============================] - 20s 93ms/step - loss: 1.0007 - val_loss: 1.2841\n",
      "Epoch 20/50\n",
      "211/211 [==============================] - 18s 86ms/step - loss: 0.9866 - val_loss: 1.2672\n",
      "Epoch 21/50\n",
      "211/211 [==============================] - 23s 111ms/step - loss: 0.9733 - val_loss: 1.2528\n",
      "Epoch 22/50\n",
      "211/211 [==============================] - 22s 103ms/step - loss: 0.9611 - val_loss: 1.2401\n",
      "Epoch 23/50\n",
      "211/211 [==============================] - 19s 91ms/step - loss: 0.9498 - val_loss: 1.2288\n",
      "Epoch 24/50\n",
      "211/211 [==============================] - 20s 94ms/step - loss: 0.9393 - val_loss: 1.2177\n",
      "Epoch 25/50\n",
      "211/211 [==============================] - 20s 95ms/step - loss: 0.9295 - val_loss: 1.2085\n",
      "Epoch 26/50\n",
      "211/211 [==============================] - 18s 86ms/step - loss: 0.9202 - val_loss: 1.2002\n",
      "Epoch 27/50\n",
      "211/211 [==============================] - 18s 84ms/step - loss: 0.9113 - val_loss: 1.1913\n",
      "Epoch 28/50\n",
      "211/211 [==============================] - 17s 81ms/step - loss: 0.9029 - val_loss: 1.1833\n",
      "Epoch 29/50\n",
      "211/211 [==============================] - 17s 81ms/step - loss: 0.8950 - val_loss: 1.1766\n",
      "Epoch 30/50\n",
      "211/211 [==============================] - 17s 82ms/step - loss: 0.8875 - val_loss: 1.1706\n",
      "Epoch 31/50\n",
      "211/211 [==============================] - 18s 83ms/step - loss: 0.8802 - val_loss: 1.1640\n",
      "Epoch 32/50\n",
      "211/211 [==============================] - 18s 83ms/step - loss: 0.8733 - val_loss: 1.1581\n",
      "Epoch 33/50\n",
      "211/211 [==============================] - 18s 85ms/step - loss: 0.8665 - val_loss: 1.1509\n",
      "Epoch 34/50\n",
      "211/211 [==============================] - 18s 84ms/step - loss: 0.8601 - val_loss: 1.1455\n",
      "Epoch 35/50\n",
      "211/211 [==============================] - 20s 93ms/step - loss: 0.8538 - val_loss: 1.1395\n",
      "Epoch 36/50\n",
      "211/211 [==============================] - 19s 91ms/step - loss: 0.8477 - val_loss: 1.1348\n",
      "Epoch 37/50\n",
      "211/211 [==============================] - 19s 88ms/step - loss: 0.8418 - val_loss: 1.1303\n",
      "Epoch 38/50\n",
      "211/211 [==============================] - 19s 88ms/step - loss: 0.8361 - val_loss: 1.1264\n",
      "Epoch 39/50\n",
      "211/211 [==============================] - 30s 145ms/step - loss: 0.8304 - val_loss: 1.1205\n",
      "Epoch 40/50\n",
      "211/211 [==============================] - 23s 107ms/step - loss: 0.8248 - val_loss: 1.1152\n",
      "Epoch 41/50\n",
      "211/211 [==============================] - 22s 102ms/step - loss: 0.8194 - val_loss: 1.1119\n",
      "Epoch 42/50\n",
      "211/211 [==============================] - 20s 94ms/step - loss: 0.8143 - val_loss: 1.1070\n",
      "Epoch 43/50\n",
      "211/211 [==============================] - 21s 99ms/step - loss: 0.8091 - val_loss: 1.1036\n",
      "Epoch 44/50\n",
      "211/211 [==============================] - 20s 97ms/step - loss: 0.8041 - val_loss: 1.0992\n",
      "Epoch 45/50\n",
      "211/211 [==============================] - 20s 93ms/step - loss: 0.7992 - val_loss: 1.0966\n",
      "Epoch 46/50\n",
      "211/211 [==============================] - 22s 105ms/step - loss: 0.7944 - val_loss: 1.0927\n",
      "Epoch 47/50\n",
      "211/211 [==============================] - 21s 102ms/step - loss: 0.7899 - val_loss: 1.0891\n",
      "Epoch 48/50\n",
      "211/211 [==============================] - 20s 94ms/step - loss: 0.7856 - val_loss: 1.0868\n",
      "Epoch 49/50\n",
      "211/211 [==============================] - 20s 95ms/step - loss: 0.7814 - val_loss: 1.0859\n",
      "Epoch 50/50\n",
      "211/211 [==============================] - 20s 95ms/step - loss: 0.7772 - val_loss: 1.0824\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2d14ca2e0>"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=[encoder_input_train, decoder_input_train], y=decoder_target_train, \\\n",
    "          validation_data = ([encoder_input_test, decoder_input_test], decoder_target_test),\n",
    "          batch_size=128, epochs=50)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 6. 모델 평가하기\n",
    "---\n",
    "\n",
    "단어 단위 번역기를 이용하여 훈련 데이터의 샘플과 테스트 데이터의 샘플로 번역 문장을 만들어보고 정답 문장과 번역 문장을 비교해보세요. 이전 스텝들에서 우리가 공부했던 모델의 경우 글자 단위에서 구현된 번역기이며 현재 프로젝트를 진행할 때 사용하는 모델은 단어 단위에서 구현되는 번역기입니다.\n",
    "\n",
    ">Embedding layer가 추가되기 때문에 학습했던 내용 그대로 사용할 경우 shape에서 error가 발생합니다.\n",
    ">decode sentence를 구성할 때 고민해보세요!!\n",
    "\n",
    "고민하다 풀리지 않을 경우에는 하단 내용 참고해주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_32 (InputLayer)       [(None, None)]            0         \n",
      "                                                                 \n",
      " embedding_23 (Embedding)    (None, None, 256)         1127936   \n",
      "                                                                 \n",
      " lstm_30 (LSTM)              [(None, 128),             197120    \n",
      "                              (None, 128),                       \n",
      "                              (None, 128)]                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,325,056\n",
      "Trainable params: 1,325,056\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_model = Model(inputs = encoder_inputs, outputs = encoder_states)\n",
    "encoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer \"lstm_31\" (type LSTM).\n\nShape (None, None) must have rank at least 3\n\nCall arguments received by layer \"lstm_31\" (type LSTM):\n  • inputs=['tf.Tensor(shape=(None, None), dtype=float32)', 'tf.Tensor(shape=(None, 256), dtype=float32)', 'tf.Tensor(shape=(None, 256), dtype=float32)']\n  • mask=None\n  • training=None\n  • initial_state=None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[177], line 10\u001b[0m\n\u001b[1;32m      6\u001b[0m decoder_states_inputs \u001b[39m=\u001b[39m [decoder_state_input_h, decoder_state_input_c]\n\u001b[1;32m      8\u001b[0m \u001b[39m# decoder_states_inputs를 현재 time step의 초기 상태로 사용.\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[39m# 구체적인 동작 자체는 def decode_sequence()에 구현.\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m decoder_outputs, state_h, state_c \u001b[39m=\u001b[39m decoder_lstm(decoder_inputs, initial_state \u001b[39m=\u001b[39;49m decoder_states_inputs)\n\u001b[1;32m     11\u001b[0m \u001b[39m# 현재 time step의 hidden state와 cell state를 하나의 변수에 저장.\u001b[39;00m\n\u001b[1;32m     12\u001b[0m decoder_states \u001b[39m=\u001b[39m [state_h, state_c]\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.13/envs/nlp/lib/python3.9/site-packages/keras/layers/rnn/base_rnn.py:615\u001b[0m, in \u001b[0;36mRNN.__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    613\u001b[0m \u001b[39m# Perform the call with temporarily replaced input_spec\u001b[39;00m\n\u001b[1;32m    614\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_spec \u001b[39m=\u001b[39m full_input_spec\n\u001b[0;32m--> 615\u001b[0m output \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(full_input, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    616\u001b[0m \u001b[39m# Remove the additional_specs from input spec and keep the rest. It\u001b[39;00m\n\u001b[1;32m    617\u001b[0m \u001b[39m# is important to keep since the input spec was populated by\u001b[39;00m\n\u001b[1;32m    618\u001b[0m \u001b[39m# build(), and will be reused in the stateful=True.\u001b[39;00m\n\u001b[1;32m    619\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_spec \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_spec[: \u001b[39m-\u001b[39m\u001b[39mlen\u001b[39m(additional_specs)]\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.13/envs/nlp/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.13/envs/nlp/lib/python3.9/site-packages/keras/backend.py:4794\u001b[0m, in \u001b[0;36mrnn\u001b[0;34m(step_function, inputs, initial_states, go_backwards, mask, constants, unroll, input_length, time_major, zero_output_for_mask, return_all_outputs)\u001b[0m\n\u001b[1;32m   4791\u001b[0m time_steps_t \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mshape(flatted_inputs[\u001b[39m0\u001b[39m])[\u001b[39m0\u001b[39m]\n\u001b[1;32m   4793\u001b[0m \u001b[39mfor\u001b[39;00m input_ \u001b[39min\u001b[39;00m flatted_inputs:\n\u001b[0;32m-> 4794\u001b[0m     input_\u001b[39m.\u001b[39;49mshape\u001b[39m.\u001b[39;49mwith_rank_at_least(\u001b[39m3\u001b[39;49m)\n\u001b[1;32m   4796\u001b[0m \u001b[39mif\u001b[39;00m mask \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   4797\u001b[0m     \u001b[39mif\u001b[39;00m mask\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m tf\u001b[39m.\u001b[39mbool:\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer \"lstm_31\" (type LSTM).\n\nShape (None, None) must have rank at least 3\n\nCall arguments received by layer \"lstm_31\" (type LSTM):\n  • inputs=['tf.Tensor(shape=(None, None), dtype=float32)', 'tf.Tensor(shape=(None, 256), dtype=float32)', 'tf.Tensor(shape=(None, 256), dtype=float32)']\n  • mask=None\n  • training=None\n  • initial_state=None"
     ]
    }
   ],
   "source": [
    "# 이전 time step의 hidden state를 저장하는 텐서\n",
    "decoder_state_input_h = Input(shape=(256,))\n",
    "# 이전 time step의 cell state를 저장하는 텐서\n",
    "decoder_state_input_c = Input(shape=(256,))\n",
    "# 이전 time step의 hidden state와 cell state를 하나의 변수에 저장\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "# decoder_states_inputs를 현재 time step의 초기 상태로 사용.\n",
    "# 구체적인 동작 자체는 def decode_sequence()에 구현.\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state = decoder_states_inputs)\n",
    "# 현재 time step의 hidden state와 cell state를 하나의 변수에 저장.\n",
    "decoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng2idx = eng_tokenizer.word_index\n",
    "fra2idx = fra_tokenizer.word_index\n",
    "idx2eng = eng_tokenizer.index_word\n",
    "idx2fra = fra_tokenizer.index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # 입력으로부터 인코더의 상태를 얻음\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # 에 해당하는 원-핫 벡터 생성\n",
    "    target_seq = np.zeros((1,1)) \n",
    "    target_seq[0, 0] = fra2idx['\\t']\n",
    "    \n",
    "    stop_condition = False\n",
    "    decoded_sentence = \"\"\n",
    "\n",
    "    # stop_condition이 True가 될 때까지 루프 반복\n",
    "    while not stop_condition:\n",
    "        # 이점 시점의 상태 states_value를 현 시점의 초기 상태로 사용\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        # 예측 결과를 문자로 변환\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = idx2fra[sampled_token_index]\n",
    "\n",
    "        # 현재 시점의 예측 문자를 예측 문장에 추가\n",
    "        decoded_sentence += ' '+sampled_char\n",
    "\n",
    "        # 에 도달하거나 최대 길이를 넘으면 중단.\n",
    "        if (sampled_char == '\\n' or\n",
    "           len(decoded_sentence) > max_fra_seq_len):\n",
    "            stop_condition = True\n",
    "\n",
    "        # 현재 시점의 예측 결과를 다음 시점의 입력으로 사용하기 위해 저장     \n",
    "        target_seq = np.zeros((1, 1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # 현재 시점의 상태를 다음 시점의 상태로 사용하기 위해 저장\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'encoder_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[174], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m decode_sequence(\u001b[39m'\u001b[39;49m\u001b[39mhello my friend\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn[173], line 3\u001b[0m, in \u001b[0;36mdecode_sequence\u001b[0;34m(input_seq)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecode_sequence\u001b[39m(input_seq):\n\u001b[1;32m      2\u001b[0m     \u001b[39m# 입력으로부터 인코더의 상태를 얻음\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m     states_value \u001b[39m=\u001b[39m encoder_model\u001b[39m.\u001b[39mpredict(input_seq)\n\u001b[1;32m      5\u001b[0m     \u001b[39m# 에 해당하는 원-핫 벡터 생성\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     target_seq \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros((\u001b[39m1\u001b[39m,\u001b[39m1\u001b[39m)) \n",
      "\u001b[0;31mNameError\u001b[0m: name 'encoder_model' is not defined"
     ]
    }
   ],
   "source": [
    "decode_sequence('hello my friend')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Dec 30 2022, 12:26:09) \n[Clang 14.0.0 (clang-1400.0.29.202)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "82539e9657ddf6135d2a67b698e4c6b6f8ca39faefdcea3cd628041ec1676e2f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
