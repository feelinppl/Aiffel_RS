{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ce17ebf-41f8-4d4d-9354-4d0c48625acf",
   "metadata": {},
   "source": [
    "# <center>Deep Learning(Rock Scissors Paper)</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a5e81ee-4444-43d5-bed9-67c7add9189c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.0\n",
      "1.24.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(tf.__version__)\n",
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7002370d-b900-485b-9125-e23ce60fb728",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 데이터를 준비하자\n",
    "---\n",
    ">웹캠이 없다면?\n",
    ">\n",
    ">일단은 아래 내용을 쭉 읽고 숙지해주세요! 웹캠이 없는 경우 라는 토글에서 기다리고 있겠습니다. 물론 웹캠이 있다면 꼭 아래 내용을 따라해주세요\n",
    "\n",
    "데이터 만들기\n",
    "(1) 우리는 노트북 전면 카메라를 활용하여 가위, 바위, 보 이미지 각 100장을 만들어 볼거예요. 그런데 300장을 어느 세월에 만들까요?\n",
    "![image](https://d3s0tskafalll9.cloudfront.net/media/images/E-1-8.max-800x600.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a9ac03-a9b4-477a-a8bc-742465b4a2cb",
   "metadata": {},
   "source": [
    "걱정하지 마세요. 구글의 teachable machine 사이트에서 쉽게 데이터를 만들어볼 수 있습니다. 아래 사이트에서 Get Started 버튼을 눌러보세요. 그 다음, Image Project - Standard image model을 선택하면, Webcam을 구동해 클래스별 이미지 데이터를 직접 촬영해서 만들 수 있는 멋진 화면이 나타납니다.\n",
    "\n",
    "- https://teachablemachine.withgoogle.com/\n",
    "\n",
    "(2) 먼저 가위 이미지 데이터를 만들어 봅시다. 웹캠 앞에 가위 포즈를 취하면서 <Hold to Record> 버튼을 누르면 이미지가 캡쳐됩니다. 딥러닝 모델이 인식하기 좋게끔 여러분들 손이 잘 보이게 찍어주세요.\n",
    "\n",
    "- 여러 각도에서 찍어보세요.\n",
    "- 여러 크기로 찍어보세요.\n",
    "- 혼자하면 다양한 각도와 크기를 저장할 수 없으니, 옆 동료와 함께 하세요.\n",
    "- 좋은 데이터가 좋은 결과를 낳는다는 것을 꼭 기억하세요.\n",
    "\n",
    "![image](https://d3s0tskafalll9.cloudfront.net/media/images/E-1-9.max-800x600.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eafc2cc-0bda-4c49-80d1-3de40edce8e3",
   "metadata": {},
   "source": [
    "주의 만약 웹캠 사용 버튼을 눌렀을 때 아래 화면처럼 에러가 난다면, 브라우저에서 웹캠을 사용할 수 있는 권한을 허용해 주어야 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72e7a59-40ab-41bc-bbb8-67c994b2b1dc",
   "metadata": {},
   "source": [
    "![image](https://d3s0tskafalll9.cloudfront.net/media/images/E-1-10.max-800x600.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a48bc26-9986-4bed-b493-093083b6a35d",
   "metadata": {},
   "source": [
    "(3) 100장의 가위 이미지를 캡쳐했다면, 우상단의 메뉴 아이콘을 눌러 다운로드 합니다.\n",
    "![image](https://d3s0tskafalll9.cloudfront.net/media/original_images/E-1-11.png)\n",
    "\n",
    "(4) 가위 이미지들을 \"scissor.zip\"이라는 파일 이름으로 본인 컴퓨터에 저장해주세요. 바위와 보 이미지들에 대해서도 위 과정을 진행하세요. (각각 \"rock.zip\", \"paper.zip\" 이름으로 저장해주세요.)\n",
    "\n",
    "디렉토리 만들기\n",
    "이제 클라우드에 실습용 디렉토리 rock_scissor_paper 및 하위 디렉토리들을 만들어, 데이터셋을 올릴 차례입니다!\n",
    "\n",
    ">토막 리눅스 사용법\n",
    ">\n",
    ">mkdir -p : mkdir를 사용하여 하위 디렉토리를 생성할때 차례대로 만들지 않고 중간 디렉토리 없이 바로 그 다음 하위 디렉토리를 만들게되면 \"디렉토리를 생성할 수 없습니다.\" 라는 메시지가 나오는데, -p 옵션을 주어 생성하게 되면 자동으로 중간 단계의 디렉토리를 생성하면서 그 하위 디렉토리를 생성하게 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0209a89b-ea54-45f0-b60f-8348e6b3f4f2",
   "metadata": {},
   "source": [
    "이미지 업로드 방법\n",
    "\n",
    "1. 오른쪽 메뉴에서 Cloud Jupyter를 열어주세요.\n",
    "2. rock.zip을 올리고 싶다면 rock_scissor_paper/rock 디렉토리로 이동 후, Upload버튼을 눌러주세요. 드래그 앤 드롭도 가능합니다.\n",
    "3. 가위와 보 데이터셋에 대해서도 위 과정을 진행해주세요.\n",
    "\n",
    "여기까지 성공하셨다면 아래와 같은 구조를 갖고 있을 것입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce85b2c4-e933-46a0-9b70-330ec3718cc6",
   "metadata": {},
   "source": [
    "**데이터 불러오기 + Resize 하기**\n",
    "\n",
    "(5) 숫자 손글씨의 경우 이미지 크기가 28x28 이었기 때문에, 우리의 가위, 바위, 보 이미지도 28x28로 만들어야 합니다. 이를 위해서는 PIL 라이브러리를 사용해볼 거예요. 그러려면 먼저 라이브러리를 불러와야 겠죠?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84cc260a-4d7c-47ab-9b70-a277465f5d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1a7efb-b9da-4316-8c58-f06c82d3abb5",
   "metadata": {},
   "source": [
    "이제 가위 이미지를 불러와서 28x28 사이즈로 변경할 겁니다. 아래 코드를 실행해보세요. 이미지의 크기가 28x28 로 바뀌었나요?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fdc9c39e-bb71-4951-86b1-ff499bf65b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_images(img_path):\n",
    "    images=glob.glob(img_path + \"/*.png\")  \n",
    "    \n",
    "    print(len(images), \" images to be resized.\")\n",
    "\n",
    "    # 파일마다 모두 112*112 사이즈로 바꾸어 저장합니다.\n",
    "    target_size=(112,112)\n",
    "    for img in images:\n",
    "        old_img = Image.open(img)\n",
    "        new_img = old_img.resize(target_size,Image.ANTIALIAS)\n",
    "        new_img = new_img.convert('RGB')\n",
    "        new_img.save(img, \"JPEG\")\n",
    "    \n",
    "    print(len(images), \" images resized.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c62774dd-e731-4d08-b72a-4fe440b68f81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "839  images to be resized.\n",
      "839  images resized.\n",
      "가위 이미지 resize 완료!\n",
      "840  images to be resized.\n",
      "840  images resized.\n",
      "바위 이미지 resize 완료!\n",
      "840  images to be resized.\n",
      "840  images resized.\n",
      "보 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "# 가위 이미지가 저장된 디렉토리\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/Documents/projects/Aiffel/lms/projects/data/proj_5/train/scissor/\"\n",
    "# resize\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"가위 이미지 resize 완료!\")\n",
    "\n",
    "# 바위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/Documents/projects/Aiffel/lms/projects/data/proj_5/train/rock/\"\n",
    "\n",
    "# resize\n",
    "resize_images(image_dir_path)\n",
    "print(\"바위 이미지 resize 완료!\")\n",
    "\n",
    "# 보이미지가 저장된 디렉토리 \n",
    "image_dir_path = os.getenv(\"HOME\") + \"/Documents/projects/Aiffel/lms/projects/data/proj_5/train/paper/\"\n",
    "\n",
    "# resize\n",
    "resize_images(image_dir_path)\n",
    "print(\"보 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "eb8cde40-b633-48be-8e0a-d5027a0e6723",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_data(img_path, number_of_data=2519):  # 가위/바위/보 이미지 개수 총합에 주의하세요.\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    img_size=112\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.png'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        \n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.png'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        \n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1  \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.png'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        \n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"변환한 데이터의 이미지 개수는\", idx,\"입니다.\")\n",
    "    return imgs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "896a423c-e09e-4a4a-95c1-e6f77f04bffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "변환한 데이터의 이미지 개수는 2519 입니다.\n",
      "x_train shape: (2519, 112, 112, 3)\n",
      "y_train shape: (2519,)\n"
     ]
    }
   ],
   "source": [
    "image_dir_path = os.getenv(\"HOME\") + \"/Documents/projects/Aiffel/lms/projects/data/proj_5/train\"\n",
    "(x_train, y_train)=load_data(image_dir_path, number_of_data=2519)\n",
    "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_train shape: {}\".format(x_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e2dc5f-47ea-4796-b2c6-690b53795687",
   "metadata": {},
   "source": [
    "## 딥러닝 네트워크 설계하기\n",
    "자 이제 데이터의 준비가 끝났습니다. 이제 여러분들이 가위바위보를 인식하는 딥러닝 네트워크를 설계해 볼까요?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "23137283-a0f7-4960-b755-6a2a5ed7abc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model에 추가된 Layer 개수:  7\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_28 (Conv2D)          (None, 110, 110, 16)      448       \n",
      "                                                                 \n",
      " max_pooling2d_28 (MaxPoolin  (None, 55, 55, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_29 (Conv2D)          (None, 53, 53, 64)        9280      \n",
      "                                                                 \n",
      " max_pooling2d_29 (MaxPoolin  (None, 26, 26, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_14 (Flatten)        (None, 43264)             0         \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 32)                1384480   \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 3)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,394,307\n",
      "Trainable params: 1,394,307\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "# model을 직접 만들어 보세요.\n",
    "# Hint! model의 입력/출력부에 특히 유의해 주세요. 가위바위보 데이터셋은 MNIST 데이터셋과 어떤 점이 달라졌나요?\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(16,(3,3), activation='relu', input_shape=(112,112,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(64, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(32, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "print('Model에 추가된 Layer 개수: ', len(model.layers))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1daad9-4029-4ad2-9382-9af48b291552",
   "metadata": {},
   "source": [
    "## 딥러닝 네트워크 학습시키기\n",
    "잘 설계가 되었다면, 이제 학습을 시켜봅시다. 아마도 여러분들의 데이터는 거의 비슷비슷할 것이기 때문에 accuracy가 꽤 높게 나올 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "4b876821-2f33-4232-8a60-2f51d858df3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 1/79 [..............................] - ETA: 26s - loss: 1.1096 - accuracy: 0.3438"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-02 21:54:17.730322: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 3s 35ms/step - loss: 0.5945 - accuracy: 0.7443\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 2s 31ms/step - loss: 0.0364 - accuracy: 0.9936\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 2s 31ms/step - loss: 0.0090 - accuracy: 0.9988\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 2s 31ms/step - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 2s 31ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 2s 31ms/step - loss: 6.5694e-04 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 2s 31ms/step - loss: 4.1346e-04 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 3s 33ms/step - loss: 2.2450e-04 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 3s 32ms/step - loss: 1.3428e-04 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 2s 31ms/step - loss: 9.8719e-05 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2f291e320>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model을 학습시키는 코드를 직접 작성해 보세요.\n",
    "# Hint! model.compile()과 model.fit()을 사용해 봅시다.\n",
    "x_train_reshaped=x_train_norm.reshape( -1, 112, 112, 3)  # 데이터갯수에 -1을 쓰면 reshape시 자동계산됩니다.\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train_reshaped, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575ef97f-0203-4e13-8af2-ec174b008aca",
   "metadata": {},
   "source": [
    "## 얼마나 잘 만들었는지 확인하기(테스트)\n",
    "여러분들은 300장의 가위바위보 이미지를 만들어 모두 학습에 사용했습니다. 그러므로 테스트 데이터가 없죠. 옆 친구의 이미지 데이터 300장을 받아오세요. 그리고 그것을 테스트 데이터로 하여 test accuracy를 측정해보세요. (만약 웹캠이 없는 경우 섹션을 진행하신 경우, 이미 test 데이터셋이 준비돼있으니 친구에게 조르지 않으셔도 됩니다)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b30c61e-c0ba-4a39-8834-4421055ab6b0",
   "metadata": {},
   "source": [
    "우선 테스트용 데이터인 x_test, y_test를 만들어 봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a934caa6-8ab7-4f2f-a836-d74f75e22ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_images(img_path):\n",
    "    images=glob.glob(img_path + \"/*.jpg\")  \n",
    "    \n",
    "    print(len(images), \"images to be resized.\")\n",
    "\n",
    "    # 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "    target_size=(112,112)\n",
    "    \n",
    "    for img in images:\n",
    "        old_img=Image.open(img)\n",
    "        new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "        new_img = new_img.convert('RGB')\n",
    "        new_img.save(img, \"JPEG\")\n",
    "    \n",
    "    print(len(images), \" images resized.\")\n",
    "\n",
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ca58f893-c68d-48b8-8c51-12d54d501d13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 images to be resized.\n",
      "100  images resized.\n",
      "100 images to be resized.\n",
      "100  images resized.\n",
      "100 images to be resized.\n",
      "100  images resized.\n"
     ]
    }
   ],
   "source": [
    "# scissor\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/Documents/projects/Aiffel/lms/projects/data/proj_5/test/scissor/\"\n",
    "resize_images(image_dir_path)\n",
    "# rock\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/Documents/projects/Aiffel/lms/projects/data/proj_5/test/rock/\"\n",
    "resize_images(image_dir_path)\n",
    "# paper\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/Documents/projects/Aiffel/lms/projects/data/proj_5/test/paper/\"\n",
    "resize_images(image_dir_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "8b62bf62-39e2-41c4-a669-614e99e7bd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test_data(image_dir_path, number_of_data):  # 가위/바위/보 이미지 개수 총합에 주의하세요.\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    img_size=112\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(image_dir_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        \n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(image_dir_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        \n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1  \n",
    "    \n",
    "    for file in glob.iglob(image_dir_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        \n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"변환한 데이터의 이미지 개수는\", idx,\"입니다.\")\n",
    "    return imgs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "31ad8782-2414-418f-b87c-9f52b17c8ccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "변환한 데이터의 이미지 개수는 300 입니다.\n"
     ]
    }
   ],
   "source": [
    "# x_test, y_test를 만드는 방법은 x_train, y_train을 만드는 방법과 아주 유사합니다.\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/Documents/projects/Aiffel/lms/projects/data/proj_5/test\"\n",
    "(x_test, y_test)=load_test_data(image_dir_path, number_of_data=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "80e8cb74-01fc-4899-8782-5e219f587ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_norm = x_test / 255.0\n",
    "x_test_reshaped=x_test_norm.reshape( -1, 112, 112, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb54fac-a527-4fe0-b65f-36eb0fe4fe3b",
   "metadata": {},
   "source": [
    "테스트용 데이터가 준비되었으니, 위에서 훈련시킨 model을 사용하여 test_accuracy를 측정해 봅시다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "92a4b75c-0e6e-4dae-9fe6-1d9b0df2872b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 0s - loss: 5.1118 - accuracy: 0.3333 - 240ms/epoch - 24ms/step\n",
      "test_loss: 5.111835479736328\n",
      "test_accuracy: 0.3333333432674408\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(x_test_reshaped,y_test, verbose=2)\n",
    "print(f\"test_loss: {test_loss}\")\n",
    "print(f\"test_accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f429b33f-bd7e-4c3a-933c-34d506e3b2ee",
   "metadata": {},
   "source": [
    "## 더 좋은 네트워크 만들어보기\n",
    "시험용 데이터x_test에 대한 인식률 test accuracy가 train accuracy보다 많이 낮게 나오지는 않았나요? 만약 그렇다면 그 이유는 무엇일까요? MNIST 손글씨 데이터 때처럼 test accuracy가 train accuracy에 근접하도록 개선 방법을 찾아 봅시다.\n",
    "\n",
    "## 노드를 마치며...\n",
    "여러분 미니 프로젝트는 잘 마치셨나요? 여러분은 이번 노드를 통해 다음의 내용을 배웠습니다.\n",
    "- 이미 잘 정제된 10개 클래스의 숫자 손글씨 데이터를 분류하는 classifier 만들기\n",
    "- 정제되지 않은 웹캠 사진으로부터 데이터 만들어보기\n",
    "- 흑백 사진이 아닌 컬러 사진을 학습하는 classifier 만들기\n",
    "- 분류하고자 하는 클래스의 개수를 마음대로 조절하기 (10개에서 3개로)\n",
    "\n",
    "그러면 오늘 배운 내용을 바탕으로 마스크 쓴 사람과 안 쓴 사람을 구분하는 프로젝트도 금방 만드실 수 있겠죠? AIFFEL 입구에서 마스크 안 쓴 사람을 자동으로 감지하고 알람을 주는 시스템을 만들어 주실 용자분 계실까요?!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "bcb5b02a-09c8-4b1a-a071-f5ab6bf036ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter값 조정\n",
    "def test_dl(A,B,C,x_train_reshaped, y_train, x_test_reshaped,y_test,D=3, epoch=5):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Conv2D(A,(3,3), activation='relu', input_shape=(112,112,3)))\n",
    "    model.add(keras.layers.MaxPool2D(2,2))\n",
    "    model.add(keras.layers.Conv2D(B, (3,3), activation='relu'))\n",
    "    model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(C, activation='relu'))\n",
    "    model.add(keras.layers.Dense(D, activation='softmax'))\n",
    "    model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "    results = model.fit(x_train_reshaped, y_train, epochs=epoch, verbose = 1)\n",
    "    test_loss, test_accuracy = model.evaluate(x_test_reshaped,y_test, verbose=2)\n",
    "    \n",
    "    print(\"\\n\", f\"A = {A}\", f\"B = {B}\",f\"C = {C}\",f\"D = {D}\",f\"epoch = {epoch}\",f\"test_loss: {test_loss:.2f}\",f\"test_accuracy: {test_accuracy:.2f}\", f\"accuracy: {results.history['accuracy'][-1]: .2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b8cec2b2-a4a9-4855-9b2e-b79d9ac1bfed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      " 3/79 [>.............................] - ETA: 2s - loss: 2.0360 - accuracy: 0.2708 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-02 21:47:48.228328: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 2s 23ms/step - loss: 0.5391 - accuracy: 0.8118\n",
      "Epoch 2/5\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 0.0240 - accuracy: 0.9964\n",
      "Epoch 3/5\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 0.0129 - accuracy: 0.9976\n",
      "Epoch 4/5\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 0.0071 - accuracy: 0.9996\n",
      "Epoch 5/5\n",
      "79/79 [==============================] - 2s 22ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "10/10 - 0s - loss: 4.7755 - accuracy: 0.3333 - 239ms/epoch - 24ms/step\n",
      "\n",
      " A = 16 B = 32 C = 64 D = 3 epoch = 5 test_loss: 4.78 test_accuracy: 0.33 accuracy:  1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-02 21:47:57.172975: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "# model을 학습시키는 코드를 직접 작성해 보세요.\n",
    "# Hint! model.evaluate()을 사용해 봅시다.\n",
    "\n",
    "test_dl(16,32,64, x_train_reshaped, y_train, x_test_reshaped, y_test, D=3,epoch=5)\n",
    "# ===손글씨 이미지 데이터 903개, 테스트 300개===(train = 루안, 한준, 종호)\n",
    "# A = 8 B = 16 C = 32 D = 3 epoch = 20 test_loss: 3.17 test_accuracy: 0.47 accuracy:  0.97\n",
    "# A = 8 B = 16 C = 32 D = 3 epoch = 15 test_loss: 2.22 test_accuracy: 0.49 accuracy:  0.96\n",
    "# A = 8 B = 16 C = 32 D = 3 epoch = 20 test_loss: 4.31 test_accuracy: 0.50 accuracy:  0.96\n",
    "# A = 8 B = 32 C = 32 D = 3 epoch = 20 test_loss: 5.00 test_accuracy: 0.51 accuracy:  0.99\n",
    "# A = 8 B = 32 C = 32 D = 3 epoch = 25 test_loss: 3.90 test_accuracy: 0.51 accuracy:  1.00\n",
    "# A = 16 B = 32 C = 32 D = 3 epoch = 25 test_loss: 6.91 test_accuracy: 0.48 accuracy:  1.00\n",
    "# A = 16 B = 32 C = 32 D = 3 epoch = 20 test_loss: 4.19 test_accuracy: 0.53 accuracy:  1.00\n",
    "# A = 16 B = 32 C = 32 D = 3 epoch = 15 test_loss: 3.45 test_accuracy: 0.50 accuracy:  0.98\n",
    "# A = 16 B = 32 C = 128 D = 3 epoch = 25 test_loss: 6.82 test_accuracy: 0.52 accuracy:  1.00\n",
    "# A = 32 B = 64 C = 128 D = 3 epoch = 25 test_loss: 6.88 test_accuracy: 0.47 accuracy:  1.00\n",
    "# ====optimizer = rmsprop\n",
    "# A = 32 B = 64 C = 256 D = 3 epoch = 25 test_loss: 7.21 test_accuracy: 0.50 accuracy:  0.99\n",
    "# A = 16 B = 32 C = 64 D = 3 epoch = 15 test_loss: 4.95 test_accuracy: 0.47 accuracy:  0.95\n",
    "# A = 16 B = 32 C = 32 D = 3 epoch = 15 test_loss: 3.47 test_accuracy: 0.48 accuracy:  0.96\n",
    "# A = 16 B = 32 C = 32 D = 3 epoch = 25 test_loss: 2.97 test_accuracy: 0.54 accuracy:  0.98\n",
    "# ====optimizer = SGD\n",
    "# A = 32 B = 32 C = 64 D = 3 epoch = 30 test_loss: 1.71 test_accuracy: 0.44 accuracy:  0.78\n",
    "# ==== train/test Data 변경 - kaggle rock, scissor, paper Data / optimaizer = adam / test_Data = 경환님데이터\n",
    "# A = 16 B = 32 C = 64 D = 3 epoch = 5 test_loss: 1.03 test_accuracy: 1.00 accuracy:  1.00"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa20157-d398-4dbd-a982-f299ae8670d4",
   "metadata": {},
   "source": [
    "# \"GIGO!!\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_mac",
   "language": "python",
   "name": "tf_mac"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
